{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN on breakout\n",
    "\n",
    "Done with reference to Denny Britz's DQN implementation found at\n",
    "https://github.com/dennybritz/reinforcement-learning/blob/master/DQN/Deep%20Q%20Learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym.wrappers import Monitor\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    A replay buffer for implementing experience replay\n",
    "    \"\"\"\n",
    "    def __init__(self, size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            size: the size of the replay buffer, items will be evicted in a FIFO manner\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        self.buffer = []\n",
    "        \n",
    "    def add(self, state, action, reward, next_state, is_terminal):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            state\n",
    "            action\n",
    "            reward\n",
    "            next_state\n",
    "            is_terminal\n",
    "            \n",
    "        Store experience into replay buffer, evicting old experience if buffer is full\n",
    "        \"\"\"\n",
    "        if len(self.buffer) >= self.size:\n",
    "            self.buffer.pop(0)\n",
    "        self.buffer.append([state, action, reward, next_state, is_terminal])\n",
    "        \n",
    "    def sample(self, no_of_samples):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            no_of_sample: number of samples desired\n",
    "            \n",
    "        Return:\n",
    "            samples of length no_of_sample\n",
    "            \n",
    "        Samples from replay buffer\n",
    "        \"\"\"\n",
    "        idx = np.random.choice(len(self.buffer), no_of_samples)\n",
    "        return np.array(self.buffer)[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/dennybritz/reinforcement-learning/blob/master/DQN/Deep%20Q%20Learning.ipynb\n",
    "class StateProcessor():\n",
    "    \"\"\"\n",
    "    Processes a raw Atari images. Resizes it and converts it to grayscale.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Build the Tensorflow graph\n",
    "        with tf.variable_scope(\"state_processor\"):\n",
    "            self.input_state = tf.placeholder(shape=[210, 160, 3], dtype=tf.uint8)\n",
    "            self.output = tf.image.rgb_to_grayscale(self.input_state)\n",
    "            self.output = tf.image.crop_to_bounding_box(self.output, 34, 0, 160, 160)\n",
    "            self.output = tf.image.resize_images(\n",
    "                self.output, [84, 84], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "            self.output = tf.squeeze(self.output)\n",
    "\n",
    "    def process(self, sess, state):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sess: A Tensorflow session object\n",
    "            state: A [210, 160, 3] Atari RGB State\n",
    "\n",
    "        Returns:\n",
    "            A processed [84, 84, 1] state representing grayscale values.\n",
    "        \"\"\"\n",
    "        return sess.run(self.output, { self.input_state: state })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(shape):\n",
    "    W = tf.get_variable('W', initializer=tf.truncated_normal(shape, mean=0, stddev=0.1))\n",
    "    return W\n",
    "\n",
    "def bias_init(shape):\n",
    "    b = tf.get_variable('b', initializer=tf.constant(0.1, shape=shape))\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork:\n",
    "    def __init__(self, frame_size, no_of_frame, no_of_actions, global_step, scope='Estimator', summaries_dir=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            frame_size: width and height of a single frame\n",
    "            no_of_frame: number of frames stacked\n",
    "            no_of_actions: number of actions (i.e output neurons), this varies from game to game\n",
    "            scope: name of scope. Used to distinguish target and estimator network\n",
    "        \"\"\"\n",
    "        self.scope = scope\n",
    "        self.summary_writer = None\n",
    "        self.step = 0\n",
    "        with tf.variable_scope(scope):\n",
    "            # build summary writer\n",
    "            if summaries_dir:\n",
    "                summary_dir = os.path.join(summaries_dir, \"summaries_{}\".format(scope))\n",
    "                if not os.path.exists(summary_dir):\n",
    "                    os.makedirs(summary_dir)\n",
    "                self.summary_writer = tf.summary.FileWriter(summary_dir)\n",
    "            \n",
    "            \n",
    "            self.X = tf.placeholder(tf.uint8, shape=[None, frame_size, frame_size, no_of_frame], name='X')\n",
    "            self.targets = tf.placeholder(tf.float32, shape=[None], name='targets')\n",
    "            self.selected_actions = tf.placeholder(tf.int32, shape=[None], name='actions')\n",
    "            X = tf.to_float(self.X) / 255.0\n",
    "            batch_size = tf.shape(self.X)[0]\n",
    "            \n",
    "            with tf.variable_scope('conv1'):\n",
    "                W1 = weights_init([8,8, no_of_frame, 32])\n",
    "                b1 = bias_init([32])\n",
    "                conv1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1,4,4,1], padding='VALID') + b1)\n",
    "            with tf.variable_scope('conv2'):\n",
    "                W2 = weights_init([4,4, 32, 64])\n",
    "                b2 = bias_init([64])\n",
    "                conv2 = tf.nn.relu(tf.nn.conv2d(conv1, W2, strides=[1,2,2,1], padding='VALID') + b2)\n",
    "            with tf.variable_scope('conv3'):\n",
    "                W3 = weights_init([3,3, 64, 64])\n",
    "                b3 = bias_init([64])\n",
    "                conv3 = tf.nn.relu(tf.nn.conv2d(conv2, W3, strides=[1,1,1,1], padding='VALID') + b3)\n",
    "                final_conv_width = (((frame_size - 8)//4 + 1 - 4)//2 + 1 - 3) + 1\n",
    "            with tf.variable_scope('fc4'):\n",
    "                W4 = weights_init([final_conv_width**2 * 64, 512])\n",
    "                b4 = bias_init([512])\n",
    "                flattened = tf.reshape(conv3, [-1, final_conv_width**2 * 64])\n",
    "                fc4 = tf.nn.relu(tf.matmul(flattened, W4) + b4)\n",
    "            with tf.variable_scope('fc5'):\n",
    "                W5 = weights_init([512, no_of_actions])\n",
    "                b5 = bias_init([no_of_actions])\n",
    "                self.predictions = tf.matmul(fc4, W5) + b5\n",
    "\n",
    "            # compute loss\n",
    "            # we need to extract the action values of selected actions\n",
    "            # to do that, we will flatten the predictions into a 1d array\n",
    "            # we then transform the action index to an index compatible with this 1d array\n",
    "            # we transform the action index by adding the action index to the offset for each row\n",
    "            # reference from\n",
    "            # https://github.com/dennybritz/reinforcement-learning/blob/master/DQN/Deep%20Q%20Learning.ipynb\n",
    "            with tf.variable_scope('loss'):\n",
    "                gather_indices = tf.range(batch_size) * tf.shape(self.predictions)[1] + self.selected_actions\n",
    "                self.action_predictions = tf.gather(tf.reshape(self.predictions, [-1]), gather_indices)\n",
    "\n",
    "                self.losses = tf.squared_difference(self.targets, self.action_predictions)\n",
    "                self.loss = tf.reduce_mean(self.losses)\n",
    "\n",
    "            # create train op\n",
    "            # I am neglecting error clipping that was used in the paper\n",
    "                self.optimizer = tf.train.RMSPropOptimizer(0.00025, 0.99, 0.0, 1e-6)\n",
    "                self.train_op = self.optimizer.minimize(self.loss, \n",
    "                                                        var_list=[W1, b1, W2, b2, W3, b3, W4, b4, W5, b5],\n",
    "                                                        global_step=global_step)\n",
    "            \n",
    "            # Summaries for Tensorboard\n",
    "            self.summaries = tf.summary.merge([\n",
    "                tf.summary.scalar(\"loss\", self.loss),\n",
    "                tf.summary.histogram(\"loss_hist\", self.losses),\n",
    "                tf.summary.histogram(\"q_values_hist\", self.predictions),\n",
    "                tf.summary.scalar(\"max_q_value\", tf.reduce_max(self.predictions))\n",
    "            ])\n",
    "            \n",
    "    def predict(self, sess, s):\n",
    "        \"\"\"\n",
    "        Predicts action values.\n",
    "\n",
    "        Args:\n",
    "          sess: Tensorflow session\n",
    "          s: State input of shape [batch_size, frame_size, frame_size, no_of_frames]\n",
    "\n",
    "        Returns:\n",
    "          Tensor of shape [batch_size, no_of_actions] containing the estimated \n",
    "          action values.\n",
    "        \"\"\"\n",
    "        return sess.run(self.predictions, { self.X: s })\n",
    "\n",
    "    def update(self, sess, s, a, targets):\n",
    "        \"\"\"\n",
    "        Updates the network towards the given targets.\n",
    "\n",
    "        Args:\n",
    "          sess: Tensorflow session object\n",
    "          s: State input of shape [batch_size, frame_size, frame_size, no_of_frames]\n",
    "          a: Chosen actions of shape [batch_size]\n",
    "          targets: Targets of shape [batch_size]\n",
    "\n",
    "        Returns:\n",
    "          The calculated loss on the batch.\n",
    "        \"\"\"\n",
    "        feed_dict = { self.X: s, self.targets: targets, self.selected_actions: a }\n",
    "        summaries, _, loss, step = sess.run(\n",
    "            [self.summaries, self.train_op, self.loss, global_step],\n",
    "            feed_dict)\n",
    "        if self.summary_writer:\n",
    "            self.summary_writer.add_summary(summaries, step)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/dennybritz/reinforcement-learning/blob/master/DQN/Deep%20Q%20Learning.ipynb\n",
    "def copy_model_parameters(sess, network1, network2):\n",
    "    \"\"\"\n",
    "    Copies the model parameters of one estimator to another.\n",
    "\n",
    "    Args:\n",
    "      sess: Tensorflow session instance\n",
    "      estimator1: Estimator to copy the paramters from\n",
    "      estimator2: Estimator to copy the parameters to\n",
    "    \"\"\"\n",
    "    n1_params = [t for t in tf.trainable_variables() if t.name.startswith(network1.scope)]\n",
    "    n1_params = sorted(n1_params, key=lambda v: v.name)\n",
    "    n2_params = [t for t in tf.trainable_variables() if t.name.startswith(network2.scope)]\n",
    "    n2_params = sorted(n2_params, key=lambda v: v.name)\n",
    "\n",
    "    update_ops = []\n",
    "    for n1_v, n2_v in zip(n1_params, n2_params):\n",
    "        op = n2_v.assign(n1_v)\n",
    "        update_ops.append(op)\n",
    "\n",
    "    sess.run(update_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(sess, env, q_network, state, epsilon, e_greedy=True):\n",
    "    if e_greedy and np.random.uniform() < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        action_values = q_network.predict(sess, np.expand_dims(state, 0))\n",
    "        return np.argmax(action_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(sess,\n",
    "              env,\n",
    "              q_network,\n",
    "              target_network,\n",
    "              state_processor,\n",
    "              num_episodes,\n",
    "              global_step,\n",
    "              experiment_dir,\n",
    "              replay_buffer,\n",
    "              buffer_init_size,\n",
    "              target_interval,\n",
    "              frame_skip,\n",
    "              epsilon_start,\n",
    "              epsilon_end,\n",
    "              epsilon_decay_length,\n",
    "              gamma,\n",
    "              batch_size):\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        buffer_init_size: no of frames used to initialize replay buffer\n",
    "        frame_skip: no. of frames to skip between decision (paper used 4)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Keeps track of useful statistics\n",
    "    episode_lengths=np.zeros(num_episodes)\n",
    "    episode_rewards=np.zeros(num_episodes)\n",
    "\n",
    "    # Create directories for checkpoints and summaries\n",
    "    checkpoint_dir = os.path.join(experiment_dir, \"checkpoints\")\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, \"model\")\n",
    "    monitor_path = os.path.join(experiment_dir, \"monitor\")\n",
    "\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    if not os.path.exists(monitor_path):\n",
    "        os.makedirs(monitor_path)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    # Load a previous checkpoint if we find one\n",
    "    latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    if latest_checkpoint:\n",
    "        print(\"Loading model checkpoint {}...\\n\".format(latest_checkpoint))\n",
    "        saver.restore(sess, latest_checkpoint)\n",
    "        \n",
    "    total_t = sess.run(global_step)\n",
    "    \n",
    "    # The epsilon decay schedule\n",
    "    epsilons = np.linspace(epsilon_start, epsilon_end, epsilon_decay_length)\n",
    "    \n",
    "    last_4_frame = []\n",
    "    \n",
    "    # init replay buffer\n",
    "    print(\"Populating replay memory...\")\n",
    "    observation = env.reset()\n",
    "    observation = state_processor.process(sess, observation)\n",
    "    # populate last 4 frames\n",
    "    last_4_frame = [observation.tolist()] * 4\n",
    "    \n",
    "    for i in range(buffer_init_size):\n",
    "        if i % 1000 == 0:\n",
    "            print(\"\\rpopulating buffer: %d\" %i, end=\"\")\n",
    "        current_state = np.stack(last_4_frame, axis=2)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        observation = state_processor.process(sess, observation)\n",
    "        last_4_frame.pop(0)\n",
    "        last_4_frame.append(observation)\n",
    "        next_state = np.stack(last_4_frame, axis=2)\n",
    "        replay_buffer.add(current_state, action, reward, next_state, done)\n",
    "        if done:\n",
    "            observation = env.reset()\n",
    "            observation = state_processor.process(sess, observation)\n",
    "            # populate last 4 frames\n",
    "            last_4_frame = [observation.tolist()] * 4\n",
    "            \n",
    "        \n",
    "    print(\"\\nPopulated replay memory\")\n",
    "    \n",
    "    # this can only be done after populating replay buffer\n",
    "    should_record = False\n",
    "    # set up env to record video near the end of training\n",
    "    env = Monitor(env, directory='./', resume=True, video_callable=lambda count: should_record and count % 10 == 0)\n",
    "    \n",
    "    \n",
    "    action = None\n",
    "\n",
    "    for i_episode in range(num_episodes):\n",
    "        # Save the current checkpoint\n",
    "        saver.save(tf.get_default_session(), checkpoint_path)\n",
    "        \n",
    "        # if is last 4 episode, record video\n",
    "        if i_episode >= num_episodes - 4 or i_episode % 5000 == 0:\n",
    "            should_record = False\n",
    "        else:\n",
    "            should_record = False\n",
    "\n",
    "        # Reset the environment\n",
    "        observation = env.reset()\n",
    "        observation = state_processor.process(sess, observation)\n",
    "        last_4_frame = [observation.tolist()] * 4\n",
    "        loss = None\n",
    "        current_state = np.stack(last_4_frame, axis=2)\n",
    "        for t in itertools.count():\n",
    "            # Epsilon for this time step\n",
    "            epsilon = epsilons[min(total_t, epsilon_decay_length-1)]\n",
    "\n",
    "            # Add epsilon to Tensorboard\n",
    "            episode_summary = tf.Summary()\n",
    "            episode_summary.value.add(simple_value=epsilon, tag=\"epsilon\")\n",
    "            q_network.summary_writer.add_summary(episode_summary, total_t)\n",
    "            \n",
    "            # update the target network\n",
    "            if total_t % target_interval == 0:\n",
    "                copy_model_parameters(sess, q_network, target_network)\n",
    "                \n",
    "            \n",
    "            if t % frame_skip == 0:\n",
    "                # only make decision every k (frame_skip) steps\n",
    "                action = select_action(sess, env, q_network, current_state, epsilon, e_greedy=True)\n",
    "                \n",
    "            # Print out which step we're on, useful for debugging.\n",
    "            print(\"\\rStep {} ({}) @ Episode {}/{}, loss: {}\".format(\n",
    "                    t, total_t, i_episode + 1, num_episodes, loss), end=\"\")\n",
    "            \n",
    "            observation, reward, done, _ = env.step(action)\n",
    "            observation = state_processor.process(sess, observation)\n",
    "            last_4_frame.pop(0)\n",
    "            last_4_frame.append(observation)\n",
    "            next_state = np.stack(last_4_frame, axis=2)\n",
    "            replay_buffer.add(current_state, action, reward, next_state, done)\n",
    "            \n",
    "            # Update statistics\n",
    "            episode_rewards[i_episode] += reward\n",
    "            episode_lengths[i_episode] = t\n",
    "            \n",
    "            # train\n",
    "            samples = replay_buffer.sample(batch_size)\n",
    "            states = []\n",
    "            actions = []\n",
    "            targets = []\n",
    "            for s, a, r, next_s, d in samples:\n",
    "                states.append(s)\n",
    "                actions.append(a)\n",
    "                # compute target\n",
    "                qs = target_network.predict(sess, np.expand_dims(next_s, 0))\n",
    "                qmax = np.max(qs)\n",
    "                if r > 0:\n",
    "                    r_clip = 1\n",
    "                elif r < 0:\n",
    "                    r_clip = -1\n",
    "                else:\n",
    "                    r_clip = 0\n",
    "                targets.append(r_clip + gamma * qmax * (1-int(d)))\n",
    "            loss = q_network.update(sess, states, actions, targets)\n",
    "                \n",
    "            \n",
    "                \n",
    "                \n",
    "            current_state = next_state\n",
    "            total_t += 1\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        print(\"\\nEpisode {}, Reward: {}\".format(i_episode + 1, episode_rewards[i_episode]))\n",
    "        # Add summaries to tensorboard\n",
    "        episode_summary = tf.Summary()\n",
    "        episode_summary.value.add(simple_value=episode_rewards[i_episode], node_name=\"episode_reward\", tag=\"episode_reward\")\n",
    "        episode_summary.value.add(simple_value=episode_lengths[i_episode], node_name=\"episode_length\", tag=\"episode_length\")\n",
    "        q_network.summary_writer.add_summary(episode_summary, total_t)\n",
    "        q_network.summary_writer.flush()\n",
    "    \n",
    "    env.close()\n",
    "    return episode_rewards, episode_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-01-05 12:46:33,837] Making new env: Breakout-v0\n",
      "/home/kai/rl/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model checkpoint /home/kai/rl/gym/dqn/experiments/Breakout-v0/checkpoints/model...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /home/kai/rl/gym/dqn/experiments/Breakout-v0/checkpoints/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-01-05 12:46:35,456] Restoring parameters from /home/kai/rl/gym/dqn/experiments/Breakout-v0/checkpoints/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating replay memory...\n",
      "populating buffer: 9000\n",
      "Populated replay memory\n",
      "Step 482 (527197) @ Episode 1/5000, loss: 0.020171679556369788\n",
      "Episode 1, Reward: 6.0\n",
      "Step 462 (527660) @ Episode 2/5000, loss: 0.023435108363628387\n",
      "Episode 2, Reward: 6.0\n",
      "Step 420 (528081) @ Episode 3/5000, loss: 0.092802062630653383\n",
      "Episode 3, Reward: 5.0\n",
      "Step 400 (528482) @ Episode 4/5000, loss: 0.0097585208714008335\n",
      "Episode 4, Reward: 5.0\n",
      "Step 326 (528809) @ Episode 5/5000, loss: 0.047685708850622187\n",
      "Episode 5, Reward: 4.0\n",
      "Step 311 (529121) @ Episode 6/5000, loss: 0.0228598229587078176\n",
      "Episode 6, Reward: 3.0\n",
      "Step 344 (529466) @ Episode 7/5000, loss: 0.027841633185744286\n",
      "Episode 7, Reward: 4.0\n",
      "Step 328 (529795) @ Episode 8/5000, loss: 0.009873446077108383\n",
      "Episode 8, Reward: 4.0\n",
      "Step 419 (530215) @ Episode 9/5000, loss: 0.017611037939786918\n",
      "Episode 9, Reward: 6.0\n",
      "Step 396 (530612) @ Episode 10/5000, loss: 0.014920121058821678\n",
      "Episode 10, Reward: 4.0\n",
      "Step 292 (530905) @ Episode 11/5000, loss: 0.066748477518558545\n",
      "Episode 11, Reward: 3.0\n",
      "Step 439 (531345) @ Episode 12/5000, loss: 0.0216794349253177644\n",
      "Episode 12, Reward: 5.0\n",
      "Step 401 (531747) @ Episode 13/5000, loss: 0.016333622857928276\n",
      "Episode 13, Reward: 5.0\n",
      "Step 427 (532175) @ Episode 14/5000, loss: 0.147099465131759646\n",
      "Episode 14, Reward: 5.0\n",
      "Step 533 (532709) @ Episode 15/5000, loss: 0.006640073377639055\n",
      "Episode 15, Reward: 7.0\n",
      "Step 432 (533142) @ Episode 16/5000, loss: 0.009266331791877747\n",
      "Episode 16, Reward: 5.0\n",
      "Step 490 (533633) @ Episode 17/5000, loss: 0.0143604846671223645\n",
      "Episode 17, Reward: 7.0\n",
      "Step 326 (533960) @ Episode 18/5000, loss: 0.019547671079635628\n",
      "Episode 18, Reward: 3.0\n",
      "Step 455 (534416) @ Episode 19/5000, loss: 0.0176519528031349185\n",
      "Episode 19, Reward: 6.0\n",
      "Step 438 (534855) @ Episode 20/5000, loss: 0.1968396902084350635\n",
      "Episode 20, Reward: 5.0\n",
      "Step 535 (535391) @ Episode 21/5000, loss: 0.0195430666208267265\n",
      "Episode 21, Reward: 7.0\n",
      "Step 420 (535812) @ Episode 22/5000, loss: 0.041816409677267075\n",
      "Episode 22, Reward: 3.0\n",
      "Step 273 (536086) @ Episode 23/5000, loss: 0.024289743974804878\n",
      "Episode 23, Reward: 3.0\n",
      "Step 598 (536685) @ Episode 24/5000, loss: 0.0153508437797427184\n",
      "Episode 24, Reward: 9.0\n",
      "Step 411 (537097) @ Episode 25/5000, loss: 0.0225190613418817524\n",
      "Episode 25, Reward: 5.0\n",
      "Step 585 (537683) @ Episode 26/5000, loss: 0.0151535114273428925\n",
      "Episode 26, Reward: 7.0\n",
      "Step 285 (537969) @ Episode 27/5000, loss: 0.015105515718460083\n",
      "Episode 27, Reward: 3.0\n",
      "Step 678 (538648) @ Episode 28/5000, loss: 0.0135338949039578445\n",
      "Episode 28, Reward: 12.0\n",
      "Step 455 (539104) @ Episode 29/5000, loss: 0.0057800179347395976\n",
      "Episode 29, Reward: 5.0\n",
      "Step 634 (539739) @ Episode 30/5000, loss: 0.0111246528103947645\n",
      "Episode 30, Reward: 11.0\n",
      "Step 640 (540380) @ Episode 31/5000, loss: 0.028624871745705605\n",
      "Episode 31, Reward: 13.0\n",
      "Step 697 (541078) @ Episode 32/5000, loss: 0.028342284262180336\n",
      "Episode 32, Reward: 9.0\n",
      "Step 502 (541581) @ Episode 33/5000, loss: 0.040231592953205118\n",
      "Episode 33, Reward: 6.0\n",
      "Step 475 (542057) @ Episode 34/5000, loss: 0.025222374126315117\n",
      "Episode 34, Reward: 6.0\n",
      "Step 396 (542454) @ Episode 35/5000, loss: 0.017681358382105827\n",
      "Episode 35, Reward: 4.0\n",
      "Step 489 (542944) @ Episode 36/5000, loss: 0.2446026504039764466\n",
      "Episode 36, Reward: 6.0\n",
      "Step 491 (543436) @ Episode 37/5000, loss: 0.0251498185098171235\n",
      "Episode 37, Reward: 6.0\n",
      "Step 372 (543809) @ Episode 38/5000, loss: 0.042956858873367313\n",
      "Episode 38, Reward: 4.0\n",
      "Step 289 (544099) @ Episode 39/5000, loss: 0.028992019593715668\n",
      "Episode 39, Reward: 3.0\n",
      "Step 569 (544669) @ Episode 40/5000, loss: 0.018032176420092583\n",
      "Episode 40, Reward: 7.0\n",
      "Step 498 (545168) @ Episode 41/5000, loss: 0.013382017612457275\n",
      "Episode 41, Reward: 6.0\n",
      "Step 490 (545659) @ Episode 42/5000, loss: 0.072426199913024946\n",
      "Episode 42, Reward: 5.0\n",
      "Step 655 (546315) @ Episode 43/5000, loss: 0.030872058123350143\n",
      "Episode 43, Reward: 9.0\n",
      "Step 370 (546686) @ Episode 44/5000, loss: 0.0226191431283950845\n",
      "Episode 44, Reward: 3.0\n",
      "Step 311 (546998) @ Episode 45/5000, loss: 0.028892084956169134\n",
      "Episode 45, Reward: 3.0\n",
      "Step 453 (547452) @ Episode 46/5000, loss: 0.035684607923030859\n",
      "Episode 46, Reward: 5.0\n",
      "Step 582 (548035) @ Episode 47/5000, loss: 0.1299060136079788235\n",
      "Episode 47, Reward: 9.0\n",
      "Step 338 (548374) @ Episode 48/5000, loss: 0.010325801558792591\n",
      "Episode 48, Reward: 4.0\n",
      "Step 366 (548741) @ Episode 49/5000, loss: 0.018749238923192024\n",
      "Episode 49, Reward: 4.0\n",
      "Step 436 (549178) @ Episode 50/5000, loss: 0.0169327259063720765\n",
      "Episode 50, Reward: 5.0\n",
      "Step 406 (549585) @ Episode 51/5000, loss: 0.0203454196453094485\n",
      "Episode 51, Reward: 5.0\n",
      "Step 449 (550035) @ Episode 52/5000, loss: 0.0246905535459518435\n",
      "Episode 52, Reward: 5.0\n",
      "Step 439 (550475) @ Episode 53/5000, loss: 0.016073174774646766\n",
      "Episode 53, Reward: 4.0\n",
      "Step 541 (551017) @ Episode 54/5000, loss: 0.073765277862548834\n",
      "Episode 54, Reward: 6.0\n",
      "Step 472 (551490) @ Episode 55/5000, loss: 0.0318786911666393395\n",
      "Episode 55, Reward: 5.0\n",
      "Step 366 (551857) @ Episode 56/5000, loss: 0.016382772475481033\n",
      "Episode 56, Reward: 4.0\n",
      "Step 504 (552362) @ Episode 57/5000, loss: 0.015262513421475887\n",
      "Episode 57, Reward: 7.0\n",
      "Step 371 (552734) @ Episode 58/5000, loss: 0.020942766219377518\n",
      "Episode 58, Reward: 4.0\n",
      "Step 651 (553386) @ Episode 59/5000, loss: 0.253771007061004645\n",
      "Episode 59, Reward: 8.0\n",
      "Step 701 (554088) @ Episode 60/5000, loss: 0.109629660844802866\n",
      "Episode 60, Reward: 8.0\n",
      "Step 425 (554514) @ Episode 61/5000, loss: 0.018995977938175246\n",
      "Episode 61, Reward: 6.0\n",
      "Step 328 (554843) @ Episode 62/5000, loss: 0.0172204934060573585\n",
      "Episode 62, Reward: 4.0\n",
      "Step 346 (555190) @ Episode 63/5000, loss: 0.0211973302066326145\n",
      "Episode 63, Reward: 4.0\n",
      "Step 561 (555752) @ Episode 64/5000, loss: 0.1514938771724701436\n",
      "Episode 64, Reward: 8.0\n",
      "Step 654 (556407) @ Episode 65/5000, loss: 0.053944792598485955\n",
      "Episode 65, Reward: 9.0\n",
      "Step 302 (556710) @ Episode 66/5000, loss: 0.011700550094246864\n",
      "Episode 66, Reward: 3.0\n",
      "Step 481 (557192) @ Episode 67/5000, loss: 0.015660578384995466\n",
      "Episode 67, Reward: 5.0\n",
      "Step 379 (557572) @ Episode 68/5000, loss: 0.0675182715058326765\n",
      "Episode 68, Reward: 4.0\n",
      "Step 438 (558011) @ Episode 69/5000, loss: 0.0129942344501614575\n",
      "Episode 69, Reward: 6.0\n",
      "Step 405 (558417) @ Episode 70/5000, loss: 0.021526841446757317\n",
      "Episode 70, Reward: 5.0\n",
      "Step 612 (559030) @ Episode 71/5000, loss: 0.028034798800945282\n",
      "Episode 71, Reward: 9.0\n",
      "Step 500 (559531) @ Episode 72/5000, loss: 0.0339805036783218435\n",
      "Episode 72, Reward: 6.0\n",
      "Step 650 (560182) @ Episode 73/5000, loss: 0.0749503299593925585\n",
      "Episode 73, Reward: 8.0\n",
      "Step 293 (560476) @ Episode 74/5000, loss: 0.007946867495775223\n",
      "Episode 74, Reward: 3.0\n",
      "Step 646 (561123) @ Episode 75/5000, loss: 0.0276217348873615265\n",
      "Episode 75, Reward: 9.0\n",
      "Step 346 (561470) @ Episode 76/5000, loss: 0.017519339919090275\n",
      "Episode 76, Reward: 7.0\n",
      "Step 373 (561844) @ Episode 77/5000, loss: 0.015666993334889412\n",
      "Episode 77, Reward: 4.0\n",
      "Step 301 (562146) @ Episode 78/5000, loss: 0.035215418785810471\n",
      "Episode 78, Reward: 3.0\n",
      "Step 596 (562743) @ Episode 79/5000, loss: 0.025085546076297766\n",
      "Episode 79, Reward: 9.0\n",
      "Step 472 (563216) @ Episode 80/5000, loss: 0.0480289869010448465\n",
      "Episode 80, Reward: 6.0\n",
      "Step 429 (563646) @ Episode 81/5000, loss: 0.0176667030900716785\n",
      "Episode 81, Reward: 5.0\n",
      "Step 429 (564076) @ Episode 82/5000, loss: 0.009488484822213657\n",
      "Episode 82, Reward: 5.0\n",
      "Step 687 (564764) @ Episode 83/5000, loss: 0.012436134740710258\n",
      "Episode 83, Reward: 10.0\n",
      "Step 367 (565132) @ Episode 84/5000, loss: 0.026654578745365143\n",
      "Episode 84, Reward: 3.0\n",
      "Step 411 (565544) @ Episode 85/5000, loss: 0.016277113929390907\n",
      "Episode 85, Reward: 5.0\n",
      "Step 389 (565934) @ Episode 86/5000, loss: 0.334570348262786875\n",
      "Episode 86, Reward: 5.0\n",
      "Step 394 (566329) @ Episode 87/5000, loss: 0.015656407922506332\n",
      "Episode 87, Reward: 5.0\n",
      "Step 373 (566703) @ Episode 88/5000, loss: 0.017827073112130165\n",
      "Episode 88, Reward: 3.0\n",
      "Step 326 (567030) @ Episode 89/5000, loss: 0.025519859045743942\n",
      "Episode 89, Reward: 3.0\n",
      "Step 517 (567548) @ Episode 90/5000, loss: 0.012505974620580673\n",
      "Episode 90, Reward: 6.0\n",
      "Step 414 (567963) @ Episode 91/5000, loss: 0.021656215190887455\n",
      "Episode 91, Reward: 5.0\n",
      "Step 426 (568390) @ Episode 92/5000, loss: 0.014449205249547958\n",
      "Episode 92, Reward: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 624 (569015) @ Episode 93/5000, loss: 0.034873709082603455\n",
      "Episode 93, Reward: 9.0\n",
      "Step 281 (569297) @ Episode 94/5000, loss: 0.012183896265923977\n",
      "Episode 94, Reward: 3.0\n",
      "Step 446 (569744) @ Episode 95/5000, loss: 0.015408316627144814\n",
      "Episode 95, Reward: 5.0\n",
      "Step 413 (570158) @ Episode 96/5000, loss: 0.031660355627536774\n",
      "Episode 96, Reward: 5.0\n",
      "Step 462 (570621) @ Episode 97/5000, loss: 0.0232321005314588556\n",
      "Episode 97, Reward: 6.0\n",
      "Step 633 (571255) @ Episode 98/5000, loss: 0.0199116282165050585\n",
      "Episode 98, Reward: 8.0\n",
      "Step 439 (571695) @ Episode 99/5000, loss: 0.137241601943969734\n",
      "Episode 99, Reward: 3.0\n",
      "Step 571 (572267) @ Episode 100/5000, loss: 0.0205158106982707984\n",
      "Episode 100, Reward: 7.0\n",
      "Step 387 (572655) @ Episode 101/5000, loss: 0.0274873264133930265\n",
      "Episode 101, Reward: 4.0\n",
      "Step 464 (573120) @ Episode 102/5000, loss: 0.0180018544197082525\n",
      "Episode 102, Reward: 5.0\n",
      "Step 366 (573487) @ Episode 103/5000, loss: 0.009720508009195328\n",
      "Episode 103, Reward: 4.0\n",
      "Step 423 (573911) @ Episode 104/5000, loss: 0.007533868774771695\n",
      "Episode 104, Reward: 5.0\n",
      "Step 509 (574421) @ Episode 105/5000, loss: 0.048585820943117147\n",
      "Episode 105, Reward: 6.0\n",
      "Step 517 (574939) @ Episode 106/5000, loss: 0.0201245881617069245\n",
      "Episode 106, Reward: 6.0\n",
      "Step 356 (575296) @ Episode 107/5000, loss: 0.122852638363838254\n",
      "Episode 107, Reward: 4.0\n",
      "Step 753 (576050) @ Episode 108/5000, loss: 0.011662042699754238\n",
      "Episode 108, Reward: 12.0\n",
      "Step 513 (576564) @ Episode 109/5000, loss: 0.014949447475373745\n",
      "Episode 109, Reward: 6.0\n",
      "Step 357 (576922) @ Episode 110/5000, loss: 0.0364600978791713746\n",
      "Episode 110, Reward: 4.0\n",
      "Step 500 (577423) @ Episode 111/5000, loss: 0.0369002446532249455\n",
      "Episode 111, Reward: 7.0\n",
      "Step 394 (577818) @ Episode 112/5000, loss: 0.012906419113278389\n",
      "Episode 112, Reward: 5.0\n",
      "Step 446 (578265) @ Episode 113/5000, loss: 0.0306286066770553655\n",
      "Episode 113, Reward: 6.0\n",
      "Step 445 (578711) @ Episode 114/5000, loss: 0.022841848433017733\n",
      "Episode 114, Reward: 6.0\n",
      "Step 352 (579064) @ Episode 115/5000, loss: 0.0565183497965335855\n",
      "Episode 115, Reward: 4.0\n",
      "Step 530 (579595) @ Episode 116/5000, loss: 0.018662607297301292\n",
      "Episode 116, Reward: 7.0\n",
      "Step 414 (580010) @ Episode 117/5000, loss: 0.0215468145906925285\n",
      "Episode 117, Reward: 5.0\n",
      "Step 421 (580432) @ Episode 118/5000, loss: 0.016054067760705948\n",
      "Episode 118, Reward: 5.0\n",
      "Step 631 (581064) @ Episode 119/5000, loss: 0.013522156514227397\n",
      "Episode 119, Reward: 7.0\n",
      "Step 423 (581488) @ Episode 120/5000, loss: 0.036496706306934365\n",
      "Episode 120, Reward: 5.0\n",
      "Step 485 (581974) @ Episode 121/5000, loss: 0.010904913768172264\n",
      "Episode 121, Reward: 7.0\n",
      "Step 679 (582654) @ Episode 122/5000, loss: 0.0106896962970495225\n",
      "Episode 122, Reward: 8.0\n",
      "Step 472 (583127) @ Episode 123/5000, loss: 0.0100131556391716275\n",
      "Episode 123, Reward: 4.0\n",
      "Step 375 (583503) @ Episode 124/5000, loss: 0.024149652570486076\n",
      "Episode 124, Reward: 5.0\n",
      "Step 573 (584077) @ Episode 125/5000, loss: 0.0157283004373312624\n",
      "Episode 125, Reward: 7.0\n",
      "Step 335 (584413) @ Episode 126/5000, loss: 0.020718887448310852\n",
      "Episode 126, Reward: 4.0\n",
      "Step 707 (585121) @ Episode 127/5000, loss: 0.0875095948576927285\n",
      "Episode 127, Reward: 10.0\n",
      "Step 391 (585513) @ Episode 128/5000, loss: 0.019590461626648903\n",
      "Episode 128, Reward: 4.0\n",
      "Step 650 (586164) @ Episode 129/5000, loss: 0.0108073465526103975\n",
      "Episode 129, Reward: 8.0\n",
      "Step 491 (586656) @ Episode 130/5000, loss: 0.011964551173150548\n",
      "Episode 130, Reward: 5.0\n",
      "Step 497 (587154) @ Episode 131/5000, loss: 0.0165839400142431265\n",
      "Episode 131, Reward: 6.0\n",
      "Step 486 (587641) @ Episode 132/5000, loss: 0.0185393523424863855\n",
      "Episode 132, Reward: 5.0\n",
      "Step 332 (587974) @ Episode 133/5000, loss: 0.014359336346387863\n",
      "Episode 133, Reward: 3.0\n",
      "Step 478 (588453) @ Episode 134/5000, loss: 0.024146787822246557\n",
      "Episode 134, Reward: 6.0\n",
      "Step 569 (589023) @ Episode 135/5000, loss: 0.173383161425590528\n",
      "Episode 135, Reward: 8.0\n",
      "Step 732 (589756) @ Episode 136/5000, loss: 0.0141429724171757754\n",
      "Episode 136, Reward: 10.0\n",
      "Step 376 (590133) @ Episode 137/5000, loss: 0.010362183675169945\n",
      "Episode 137, Reward: 4.0\n",
      "Step 288 (590422) @ Episode 138/5000, loss: 0.021300688385963444\n",
      "Episode 138, Reward: 2.0\n",
      "Step 398 (590821) @ Episode 139/5000, loss: 0.014767528511583805\n",
      "Episode 139, Reward: 4.0\n",
      "Step 502 (591324) @ Episode 140/5000, loss: 0.033760465681552894\n",
      "Episode 140, Reward: 5.0\n",
      "Step 455 (591780) @ Episode 141/5000, loss: 0.018236123025417328\n",
      "Episode 141, Reward: 4.0\n",
      "Step 441 (592222) @ Episode 142/5000, loss: 0.019072439521551132\n",
      "Episode 142, Reward: 4.0\n",
      "Step 557 (592780) @ Episode 143/5000, loss: 0.0226779133081436166\n",
      "Episode 143, Reward: 8.0\n",
      "Step 337 (593118) @ Episode 144/5000, loss: 0.022827932611107826\n",
      "Episode 144, Reward: 3.0\n",
      "Step 349 (593468) @ Episode 145/5000, loss: 0.020946398377418518\n",
      "Episode 145, Reward: 3.0\n",
      "Step 343 (593812) @ Episode 146/5000, loss: 0.017215065658092523\n",
      "Episode 146, Reward: 3.0\n",
      "Step 609 (594422) @ Episode 147/5000, loss: 0.022862002253532417\n",
      "Episode 147, Reward: 7.0\n",
      "Step 594 (595017) @ Episode 148/5000, loss: 0.027367062866687775\n",
      "Episode 148, Reward: 8.0\n",
      "Step 489 (595507) @ Episode 149/5000, loss: 0.0194697380065917975\n",
      "Episode 149, Reward: 6.0\n",
      "Step 444 (595952) @ Episode 150/5000, loss: 0.009139469824731353\n",
      "Episode 150, Reward: 3.0\n",
      "Step 448 (596401) @ Episode 151/5000, loss: 0.0205236338078975686\n",
      "Episode 151, Reward: 3.0\n",
      "Step 531 (596933) @ Episode 152/5000, loss: 0.148537755012512284\n",
      "Episode 152, Reward: 6.0\n",
      "Step 580 (597514) @ Episode 153/5000, loss: 0.0251422561705112465\n",
      "Episode 153, Reward: 6.0\n",
      "Step 622 (598137) @ Episode 154/5000, loss: 0.0162944272160530135\n",
      "Episode 154, Reward: 7.0\n",
      "Step 297 (598435) @ Episode 155/5000, loss: 0.0224608853459358285\n",
      "Episode 155, Reward: 2.0\n",
      "Step 469 (598905) @ Episode 156/5000, loss: 0.026062719523906708\n",
      "Episode 156, Reward: 6.0\n",
      "Step 401 (599307) @ Episode 157/5000, loss: 0.017179314047098168\n",
      "Episode 157, Reward: 4.0\n",
      "Step 573 (599881) @ Episode 158/5000, loss: 0.025031335651874542\n",
      "Episode 158, Reward: 7.0\n",
      "Step 419 (600301) @ Episode 159/5000, loss: 0.038641694933176046\n",
      "Episode 159, Reward: 4.0\n",
      "Step 610 (600912) @ Episode 160/5000, loss: 0.014349318109452724\n",
      "Episode 160, Reward: 7.0\n",
      "Step 485 (601398) @ Episode 161/5000, loss: 0.025424128398299217\n",
      "Episode 161, Reward: 6.0\n",
      "Step 490 (601889) @ Episode 162/5000, loss: 0.014966003596782684\n",
      "Episode 162, Reward: 4.0\n",
      "Step 426 (602316) @ Episode 163/5000, loss: 0.024547487497329712\n",
      "Episode 163, Reward: 4.0\n",
      "Step 582 (602899) @ Episode 164/5000, loss: 0.144467413425445565\n",
      "Episode 164, Reward: 8.0\n",
      "Step 443 (603343) @ Episode 165/5000, loss: 0.0142208691686391835\n",
      "Episode 165, Reward: 5.0\n",
      "Step 435 (603779) @ Episode 166/5000, loss: 0.034521013498306274\n",
      "Episode 166, Reward: 5.0\n",
      "Step 413 (604193) @ Episode 167/5000, loss: 0.0368855074048042355\n",
      "Episode 167, Reward: 4.0\n",
      "Step 542 (604736) @ Episode 168/5000, loss: 0.0691772252321243365\n",
      "Episode 168, Reward: 5.0\n",
      "Step 563 (605300) @ Episode 169/5000, loss: 0.027458708733320236\n",
      "Episode 169, Reward: 6.0\n",
      "Step 498 (605799) @ Episode 170/5000, loss: 0.014717758633196354\n",
      "Episode 170, Reward: 2.0\n",
      "Step 472 (606272) @ Episode 171/5000, loss: 0.022109018638730056\n",
      "Episode 171, Reward: 5.0\n",
      "Step 600 (606873) @ Episode 172/5000, loss: 0.039398588240146646\n",
      "Episode 172, Reward: 9.0\n",
      "Step 308 (607182) @ Episode 173/5000, loss: 0.0138914473354816445\n",
      "Episode 173, Reward: 2.0\n",
      "Step 324 (607507) @ Episode 174/5000, loss: 0.0225567501038312925\n",
      "Episode 174, Reward: 4.0\n",
      "Step 596 (608104) @ Episode 175/5000, loss: 0.038125209510326385\n",
      "Episode 175, Reward: 6.0\n",
      "Step 512 (608617) @ Episode 176/5000, loss: 0.0214327275753021245\n",
      "Episode 176, Reward: 5.0\n",
      "Step 400 (609018) @ Episode 177/5000, loss: 0.015135684981942177\n",
      "Episode 177, Reward: 3.0\n",
      "Step 432 (609451) @ Episode 178/5000, loss: 0.0903380140662193375\n",
      "Episode 178, Reward: 5.0\n",
      "Step 442 (609894) @ Episode 179/5000, loss: 0.0230002757161855775\n",
      "Episode 179, Reward: 4.0\n",
      "Step 412 (610307) @ Episode 180/5000, loss: 0.026537369936704636\n",
      "Episode 180, Reward: 4.0\n",
      "Step 431 (610739) @ Episode 181/5000, loss: 0.0243296604603528986\n",
      "Episode 181, Reward: 2.0\n",
      "Step 688 (611428) @ Episode 182/5000, loss: 0.024032628163695335\n",
      "Episode 182, Reward: 8.0\n",
      "Step 410 (611839) @ Episode 183/5000, loss: 0.023209990933537483\n",
      "Episode 183, Reward: 4.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 726 (612566) @ Episode 184/5000, loss: 0.027775853872299194\n",
      "Episode 184, Reward: 9.0\n",
      "Step 423 (612990) @ Episode 185/5000, loss: 0.0163397751748561865\n",
      "Episode 185, Reward: 4.0\n",
      "Step 338 (613329) @ Episode 186/5000, loss: 0.028557980433106422\n",
      "Episode 186, Reward: 2.0\n",
      "Step 616 (613946) @ Episode 187/5000, loss: 0.0123034743592143064\n",
      "Episode 187, Reward: 7.0\n",
      "Step 384 (614331) @ Episode 188/5000, loss: 0.015041835606098175\n",
      "Episode 188, Reward: 2.0\n",
      "Step 423 (614755) @ Episode 189/5000, loss: 0.024739298969507217\n",
      "Episode 189, Reward: 3.0\n",
      "Step 542 (615298) @ Episode 190/5000, loss: 0.008627180010080338\n",
      "Episode 190, Reward: 6.0\n",
      "Step 612 (615911) @ Episode 191/5000, loss: 0.131799504160881044\n",
      "Episode 191, Reward: 7.0\n",
      "Step 604 (616516) @ Episode 192/5000, loss: 0.018043542280793193\n",
      "Episode 192, Reward: 5.0\n",
      "Step 482 (616999) @ Episode 193/5000, loss: 0.0123821198940277146\n",
      "Episode 193, Reward: 5.0\n",
      "Step 484 (617484) @ Episode 194/5000, loss: 0.0234638769179582685\n",
      "Episode 194, Reward: 4.0\n",
      "Step 494 (617979) @ Episode 195/5000, loss: 0.026557441800832756\n",
      "Episode 195, Reward: 7.0\n",
      "Step 529 (618509) @ Episode 196/5000, loss: 0.018989188596606255\n",
      "Episode 196, Reward: 6.0\n",
      "Step 625 (619135) @ Episode 197/5000, loss: 0.203033193945884745\n",
      "Episode 197, Reward: 8.0\n",
      "Step 469 (619605) @ Episode 198/5000, loss: 0.013952812179923058\n",
      "Episode 198, Reward: 5.0\n",
      "Step 540 (620146) @ Episode 199/5000, loss: 0.0299140177667140965\n",
      "Episode 199, Reward: 7.0\n",
      "Step 463 (620610) @ Episode 200/5000, loss: 0.012806582264602184\n",
      "Episode 200, Reward: 5.0\n",
      "Step 588 (621199) @ Episode 201/5000, loss: 0.011946648359298706\n",
      "Episode 201, Reward: 5.0\n",
      "Step 480 (621680) @ Episode 202/5000, loss: 0.015612848103046417\n",
      "Episode 202, Reward: 6.0\n",
      "Step 501 (622182) @ Episode 203/5000, loss: 0.0093832239508628855\n",
      "Episode 203, Reward: 6.0\n",
      "Step 302 (622485) @ Episode 204/5000, loss: 0.015649056062102318\n",
      "Episode 204, Reward: 3.0\n",
      "Step 658 (623144) @ Episode 205/5000, loss: 0.0206857156008481985\n",
      "Episode 205, Reward: 5.0\n",
      "Step 430 (623575) @ Episode 206/5000, loss: 0.0166463349014520655\n",
      "Episode 206, Reward: 3.0\n",
      "Step 365 (623941) @ Episode 207/5000, loss: 0.017911370843648916\n",
      "Episode 207, Reward: 3.0\n",
      "Step 507 (624449) @ Episode 208/5000, loss: 0.0295668020844459535\n",
      "Episode 208, Reward: 2.0\n",
      "Step 397 (624847) @ Episode 209/5000, loss: 0.0160330943763256075\n",
      "Episode 209, Reward: 3.0\n",
      "Step 557 (625405) @ Episode 210/5000, loss: 0.0526832304894924164\n",
      "Episode 210, Reward: 5.0\n",
      "Step 603 (626009) @ Episode 211/5000, loss: 0.462740749120712323\n",
      "Episode 211, Reward: 4.0\n",
      "Step 726 (626736) @ Episode 212/5000, loss: 0.0116761848330497744\n",
      "Episode 212, Reward: 10.0\n",
      "Step 400 (627137) @ Episode 213/5000, loss: 0.0222258586436510145\n",
      "Episode 213, Reward: 3.0\n",
      "Step 520 (627658) @ Episode 214/5000, loss: 0.0168722476810216965\n",
      "Episode 214, Reward: 5.0\n",
      "Step 281 (627940) @ Episode 215/5000, loss: 0.0140133984386920935\n",
      "Episode 215, Reward: 2.0\n",
      "Step 594 (628535) @ Episode 216/5000, loss: 0.013032039627432823\n",
      "Episode 216, Reward: 9.0\n",
      "Step 453 (628989) @ Episode 217/5000, loss: 0.0150321330875158315\n",
      "Episode 217, Reward: 4.0\n",
      "Step 358 (629348) @ Episode 218/5000, loss: 0.0216500014066696175\n",
      "Episode 218, Reward: 4.0\n",
      "Step 559 (629908) @ Episode 219/5000, loss: 0.0188615135848522275\n",
      "Episode 219, Reward: 5.0\n",
      "Step 415 (630324) @ Episode 220/5000, loss: 0.0296582803130149846\n",
      "Episode 220, Reward: 3.0\n",
      "Step 611 (630936) @ Episode 221/5000, loss: 0.0212205145508050925\n",
      "Episode 221, Reward: 7.0\n",
      "Step 457 (631394) @ Episode 222/5000, loss: 0.0297881886363029485\n",
      "Episode 222, Reward: 3.0\n",
      "Step 468 (631863) @ Episode 223/5000, loss: 0.031508155167102814\n",
      "Episode 223, Reward: 3.0\n",
      "Step 507 (632371) @ Episode 224/5000, loss: 0.0290889684110879926\n",
      "Episode 224, Reward: 6.0\n",
      "Step 276 (632648) @ Episode 225/5000, loss: 0.0202652215957641676\n",
      "Episode 225, Reward: 2.0\n",
      "Step 561 (633210) @ Episode 226/5000, loss: 0.015776330605149273\n",
      "Episode 226, Reward: 4.0\n",
      "Step 562 (633773) @ Episode 227/5000, loss: 0.0259989332407712945\n",
      "Episode 227, Reward: 5.0\n",
      "Step 615 (634389) @ Episode 228/5000, loss: 0.0119271669536829825\n",
      "Episode 228, Reward: 7.0\n",
      "Step 432 (634822) @ Episode 229/5000, loss: 0.1381358206272125286\n",
      "Episode 229, Reward: 4.0\n",
      "Step 417 (635240) @ Episode 230/5000, loss: 0.0103859389200806625\n",
      "Episode 230, Reward: 3.0\n",
      "Step 560 (635801) @ Episode 231/5000, loss: 0.006951370742172003\n",
      "Episode 231, Reward: 8.0\n",
      "Step 631 (636433) @ Episode 232/5000, loss: 0.0088270846754312524\n",
      "Episode 232, Reward: 7.0\n",
      "Step 247 (636681) @ Episode 233/5000, loss: 0.012973411008715633\n",
      "Episode 233, Reward: 1.0\n",
      "Step 403 (637085) @ Episode 234/5000, loss: 0.0202458128333091745\n",
      "Episode 234, Reward: 4.0\n",
      "Step 466 (637552) @ Episode 235/5000, loss: 0.0108078643679618846\n",
      "Episode 235, Reward: 6.0\n",
      "Step 709 (638262) @ Episode 236/5000, loss: 0.0509635731577873245\n",
      "Episode 236, Reward: 8.0\n",
      "Step 371 (638634) @ Episode 237/5000, loss: 0.0213234554976224985\n",
      "Episode 237, Reward: 4.0\n",
      "Step 507 (639142) @ Episode 238/5000, loss: 0.014243310317397118\n",
      "Episode 238, Reward: 6.0\n",
      "Step 533 (639676) @ Episode 239/5000, loss: 0.019230112433433533\n",
      "Episode 239, Reward: 5.0\n",
      "Step 336 (640013) @ Episode 240/5000, loss: 0.012778867967426777\n",
      "Episode 240, Reward: 3.0\n",
      "Step 368 (640382) @ Episode 241/5000, loss: 0.012091606855392456\n",
      "Episode 241, Reward: 3.0\n",
      "Step 505 (640888) @ Episode 242/5000, loss: 0.0511254742741584826\n",
      "Episode 242, Reward: 5.0\n",
      "Step 436 (641325) @ Episode 243/5000, loss: 0.0210393629968166354\n",
      "Episode 243, Reward: 5.0\n",
      "Step 293 (641619) @ Episode 244/5000, loss: 0.012669352814555168\n",
      "Episode 244, Reward: 2.0\n",
      "Step 531 (642151) @ Episode 245/5000, loss: 0.0144512644037604335\n",
      "Episode 245, Reward: 5.0\n",
      "Step 477 (642629) @ Episode 246/5000, loss: 0.026279048994183548\n",
      "Episode 246, Reward: 6.0\n",
      "Step 488 (643118) @ Episode 247/5000, loss: 0.0080443723127245955\n",
      "Episode 247, Reward: 5.0\n",
      "Step 394 (643513) @ Episode 248/5000, loss: 0.0101029016077518465\n",
      "Episode 248, Reward: 8.0\n",
      "Step 486 (644000) @ Episode 249/5000, loss: 0.0078523820266127596\n",
      "Episode 249, Reward: 5.0\n",
      "Step 443 (644444) @ Episode 250/5000, loss: 0.014224143698811531\n",
      "Episode 250, Reward: 3.0\n",
      "Step 395 (644840) @ Episode 251/5000, loss: 0.0156000806018710145\n",
      "Episode 251, Reward: 4.0\n",
      "Step 288 (645129) @ Episode 252/5000, loss: 0.0087519325315952374\n",
      "Episode 252, Reward: 2.0\n",
      "Step 820 (645950) @ Episode 253/5000, loss: 0.0227696634829044345\n",
      "Episode 253, Reward: 10.0\n",
      "Step 450 (646401) @ Episode 254/5000, loss: 0.0118157630786299745\n",
      "Episode 254, Reward: 6.0\n",
      "Step 372 (646774) @ Episode 255/5000, loss: 0.0318421833217144554\n",
      "Episode 255, Reward: 4.0\n",
      "Step 456 (647231) @ Episode 256/5000, loss: 0.0145185496658086784\n",
      "Episode 256, Reward: 5.0\n",
      "Step 535 (647767) @ Episode 257/5000, loss: 0.013631807640194893\n",
      "Episode 257, Reward: 5.0\n",
      "Step 359 (648127) @ Episode 258/5000, loss: 0.3370689749717712415\n",
      "Episode 258, Reward: 4.0\n",
      "Step 456 (648584) @ Episode 259/5000, loss: 0.018027663230895996\n",
      "Episode 259, Reward: 5.0\n",
      "Step 399 (648984) @ Episode 260/5000, loss: 0.0124606415629386936\n",
      "Episode 260, Reward: 4.0\n",
      "Step 636 (649621) @ Episode 261/5000, loss: 0.0150768477469682715\n",
      "Episode 261, Reward: 8.0\n",
      "Step 746 (650368) @ Episode 262/5000, loss: 0.2520281076431274435\n",
      "Episode 262, Reward: 9.0\n",
      "Step 399 (650768) @ Episode 263/5000, loss: 0.0128730861470103264\n",
      "Episode 263, Reward: 2.0\n",
      "Step 315 (651084) @ Episode 264/5000, loss: 0.0190897807478904725\n",
      "Episode 264, Reward: 2.0\n",
      "Step 441 (651526) @ Episode 265/5000, loss: 0.008780168369412422\n",
      "Episode 265, Reward: 3.0\n",
      "Step 401 (651928) @ Episode 266/5000, loss: 0.0138195836916565925\n",
      "Episode 266, Reward: 3.0\n",
      "Step 432 (652361) @ Episode 267/5000, loss: 0.0686985999345779456\n",
      "Episode 267, Reward: 4.0\n",
      "Step 357 (652719) @ Episode 268/5000, loss: 0.0115660224109888084\n",
      "Episode 268, Reward: 2.0\n",
      "Step 654 (653374) @ Episode 269/5000, loss: 0.0645842626690864626\n",
      "Episode 269, Reward: 8.0\n",
      "Step 550 (653925) @ Episode 270/5000, loss: 0.0095987841486930855\n",
      "Episode 270, Reward: 5.0\n",
      "Step 407 (654333) @ Episode 271/5000, loss: 0.0103002004325389865\n",
      "Episode 271, Reward: 3.0\n",
      "Step 668 (655002) @ Episode 272/5000, loss: 0.0092935059219598775\n",
      "Episode 272, Reward: 12.0\n",
      "Step 690 (655693) @ Episode 273/5000, loss: 0.0172659847885370255\n",
      "Episode 273, Reward: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 555 (656249) @ Episode 274/5000, loss: 0.0269485805183649065\n",
      "Episode 274, Reward: 4.0\n",
      "Step 469 (656719) @ Episode 275/5000, loss: 0.0312965884804725655\n",
      "Episode 275, Reward: 5.0\n",
      "Step 647 (657367) @ Episode 276/5000, loss: 0.0161986574530601585\n",
      "Episode 276, Reward: 8.0\n",
      "Step 755 (658123) @ Episode 277/5000, loss: 0.0380167216062545865\n",
      "Episode 277, Reward: 11.0\n",
      "Step 396 (658520) @ Episode 278/5000, loss: 0.0112065542489290245\n",
      "Episode 278, Reward: 4.0\n",
      "Step 502 (659023) @ Episode 279/5000, loss: 0.0191525612026453025\n",
      "Episode 279, Reward: 6.0\n",
      "Step 725 (659749) @ Episode 280/5000, loss: 0.0233547445386648185\n",
      "Episode 280, Reward: 5.0\n",
      "Step 373 (660123) @ Episode 281/5000, loss: 0.0224698334932327275\n",
      "Episode 281, Reward: 4.0\n",
      "Step 491 (660615) @ Episode 282/5000, loss: 0.018876731395721436\n",
      "Episode 282, Reward: 4.0\n",
      "Step 484 (661100) @ Episode 283/5000, loss: 0.0152114965021610265\n",
      "Episode 283, Reward: 3.0\n",
      "Step 514 (661615) @ Episode 284/5000, loss: 0.0120402090251445775\n",
      "Episode 284, Reward: 5.0\n",
      "Step 292 (661908) @ Episode 285/5000, loss: 0.021692177280783653\n",
      "Episode 285, Reward: 1.0\n",
      "Step 594 (662503) @ Episode 286/5000, loss: 0.0181064419448375755\n",
      "Episode 286, Reward: 3.0\n",
      "Step 425 (662929) @ Episode 287/5000, loss: 0.0134559590369462975\n",
      "Episode 287, Reward: 4.0\n",
      "Step 512 (663442) @ Episode 288/5000, loss: 0.0218977853655815125\n",
      "Episode 288, Reward: 6.0\n",
      "Step 466 (663909) @ Episode 289/5000, loss: 0.0593889914453029656\n",
      "Episode 289, Reward: 1.0\n",
      "Step 624 (664534) @ Episode 290/5000, loss: 0.0219057686626911165\n",
      "Episode 290, Reward: 8.0\n",
      "Step 357 (664892) @ Episode 291/5000, loss: 0.0166454426944255836\n",
      "Episode 291, Reward: 1.0\n",
      "Step 699 (665592) @ Episode 292/5000, loss: 0.0179010257124900825\n",
      "Episode 292, Reward: 5.0\n",
      "Step 495 (666088) @ Episode 293/5000, loss: 0.0121917752549052245\n",
      "Episode 293, Reward: 4.0\n",
      "Step 317 (666406) @ Episode 294/5000, loss: 0.0096039213240146645\n",
      "Episode 294, Reward: 2.0\n",
      "Step 587 (666994) @ Episode 295/5000, loss: 0.0160867143422365265\n",
      "Episode 295, Reward: 2.0\n",
      "Step 389 (667384) @ Episode 296/5000, loss: 0.0194942019879817965\n",
      "Episode 296, Reward: 2.0\n",
      "Step 331 (667716) @ Episode 297/5000, loss: 0.0164898745715618135\n",
      "Episode 297, Reward: 1.0\n",
      "Step 497 (668214) @ Episode 298/5000, loss: 0.0080481134355068255\n",
      "Episode 298, Reward: 4.0\n",
      "Step 409 (668624) @ Episode 299/5000, loss: 0.0242959056049585345\n",
      "Episode 299, Reward: 3.0\n",
      "Step 440 (669065) @ Episode 300/5000, loss: 0.0083210393786430364\n",
      "Episode 300, Reward: 3.0\n",
      "Step 377 (669443) @ Episode 301/5000, loss: 0.0107479654252529145\n",
      "Episode 301, Reward: 2.0\n",
      "Step 465 (669909) @ Episode 302/5000, loss: 0.0179237611591815955\n",
      "Episode 302, Reward: 3.0\n",
      "Step 393 (670303) @ Episode 303/5000, loss: 0.0100916922092437745\n",
      "Episode 303, Reward: 3.0\n",
      "Step 435 (670739) @ Episode 304/5000, loss: 0.0199569538235664375\n",
      "Episode 304, Reward: 4.0\n",
      "Step 495 (671235) @ Episode 305/5000, loss: 0.0938357040286064185\n",
      "Episode 305, Reward: 4.0\n",
      "Step 537 (671773) @ Episode 306/5000, loss: 0.0111549906432628635\n",
      "Episode 306, Reward: 6.0\n",
      "Step 451 (672225) @ Episode 307/5000, loss: 0.018700219690799713\n",
      "Episode 307, Reward: 4.0\n",
      "Step 267 (672493) @ Episode 308/5000, loss: 0.1202229931950569245\n",
      "Episode 308, Reward: 2.0\n",
      "Step 498 (672992) @ Episode 309/5000, loss: 0.0692444220185279844\n",
      "Episode 309, Reward: 4.0\n",
      "Step 660 (673653) @ Episode 310/5000, loss: 0.0112962741404771885\n",
      "Episode 310, Reward: 7.0\n",
      "Step 261 (673915) @ Episode 311/5000, loss: 0.009094362147152424\n",
      "Episode 311, Reward: 1.0\n",
      "Step 573 (674489) @ Episode 312/5000, loss: 0.0152899101376533535\n",
      "Episode 312, Reward: 4.0\n",
      "Step 378 (674868) @ Episode 313/5000, loss: 0.232162520289421088\n",
      "Episode 313, Reward: 2.0\n",
      "Step 647 (675516) @ Episode 314/5000, loss: 0.0107254311442375185\n",
      "Episode 314, Reward: 7.0\n",
      "Step 444 (675961) @ Episode 315/5000, loss: 0.0183503050357103355\n",
      "Episode 315, Reward: 2.0\n",
      "Step 468 (676430) @ Episode 316/5000, loss: 0.1471921503543853815\n",
      "Episode 316, Reward: 4.0\n",
      "Step 326 (676757) @ Episode 317/5000, loss: 0.0122596099972724915\n",
      "Episode 317, Reward: 3.0\n",
      "Step 312 (677070) @ Episode 318/5000, loss: 0.0138816423714160926\n",
      "Episode 318, Reward: 0.0\n",
      "Step 486 (677557) @ Episode 319/5000, loss: 0.0206508375704288575\n",
      "Episode 319, Reward: 4.0\n",
      "Step 409 (677967) @ Episode 320/5000, loss: 0.0139623377472162254\n",
      "Episode 320, Reward: 2.0\n",
      "Step 290 (678258) @ Episode 321/5000, loss: 0.0085850693285465245\n",
      "Episode 321, Reward: 2.0\n",
      "Step 388 (678647) @ Episode 322/5000, loss: 0.0170388165861368185\n",
      "Episode 322, Reward: 3.0\n",
      "Step 556 (679204) @ Episode 323/5000, loss: 0.0253491550683975225\n",
      "Episode 323, Reward: 4.0\n",
      "Step 519 (679724) @ Episode 324/5000, loss: 0.0440976023674011234\n",
      "Episode 324, Reward: 3.0\n",
      "Step 480 (680205) @ Episode 325/5000, loss: 0.0159860812127590185\n",
      "Episode 325, Reward: 3.0\n",
      "Step 517 (680723) @ Episode 326/5000, loss: 0.0175999589264392856\n",
      "Episode 326, Reward: 3.0\n",
      "Step 594 (681318) @ Episode 327/5000, loss: 0.0178375430405139925\n",
      "Episode 327, Reward: 3.0\n",
      "Step 512 (681831) @ Episode 328/5000, loss: 0.0095004420727491385\n",
      "Episode 328, Reward: 7.0\n",
      "Step 315 (682147) @ Episode 329/5000, loss: 0.0203125253319740375\n",
      "Episode 329, Reward: 2.0\n",
      "Step 637 (682785) @ Episode 330/5000, loss: 0.0138788446784019476\n",
      "Episode 330, Reward: 5.0\n",
      "Step 586 (683372) @ Episode 331/5000, loss: 0.0147132780402898795\n",
      "Episode 331, Reward: 6.0\n",
      "Step 386 (683759) @ Episode 332/5000, loss: 0.018884588032960891\n",
      "Episode 332, Reward: 3.0\n",
      "Step 466 (684226) @ Episode 333/5000, loss: 0.0110988542437553435\n",
      "Episode 333, Reward: 3.0\n",
      "Step 382 (684609) @ Episode 334/5000, loss: 0.0115510663017630584\n",
      "Episode 334, Reward: 1.0\n",
      "Step 340 (684950) @ Episode 335/5000, loss: 0.0130556914955377584\n",
      "Episode 335, Reward: 2.0\n",
      "Step 457 (685408) @ Episode 336/5000, loss: 0.0159520525485277184\n",
      "Episode 336, Reward: 4.0\n",
      "Step 750 (686159) @ Episode 337/5000, loss: 0.0109805995598435444\n",
      "Episode 337, Reward: 7.0\n",
      "Step 726 (686886) @ Episode 338/5000, loss: 0.0188830420374870325\n",
      "Episode 338, Reward: 7.0\n",
      "Step 322 (687209) @ Episode 339/5000, loss: 0.0237508192658424385\n",
      "Episode 339, Reward: 1.0\n",
      "Step 299 (687509) @ Episode 340/5000, loss: 0.016929676756262782\n",
      "Episode 340, Reward: 2.0\n",
      "Step 424 (687934) @ Episode 341/5000, loss: 0.0169072560966014865\n",
      "Episode 341, Reward: 2.0\n",
      "Step 508 (688443) @ Episode 342/5000, loss: 0.0294029526412487034\n",
      "Episode 342, Reward: 5.0\n",
      "Step 502 (688946) @ Episode 343/5000, loss: 0.064009636640548764\n",
      "Episode 343, Reward: 5.0\n",
      "Step 392 (689339) @ Episode 344/5000, loss: 0.0091125164180994035\n",
      "Episode 344, Reward: 2.0\n",
      "Step 531 (689871) @ Episode 345/5000, loss: 0.0149090085178613665\n",
      "Episode 345, Reward: 3.0\n",
      "Step 478 (690350) @ Episode 346/5000, loss: 0.0134901404380798345\n",
      "Episode 346, Reward: 3.0\n",
      "Step 320 (690671) @ Episode 347/5000, loss: 0.0122416438534855845\n",
      "Episode 347, Reward: 2.0\n",
      "Step 471 (691143) @ Episode 348/5000, loss: 0.0131541471928358085\n",
      "Episode 348, Reward: 5.0\n",
      "Step 254 (691398) @ Episode 349/5000, loss: 0.0160158239305019386\n",
      "Episode 349, Reward: 0.0\n",
      "Step 432 (691831) @ Episode 350/5000, loss: 0.016744291409850127\n",
      "Episode 350, Reward: 4.0\n",
      "Step 401 (692233) @ Episode 351/5000, loss: 0.0286586564034223564\n",
      "Episode 351, Reward: 1.0\n",
      "Step 605 (692839) @ Episode 352/5000, loss: 0.0114300902932882315\n",
      "Episode 352, Reward: 5.0\n",
      "Step 456 (693296) @ Episode 353/5000, loss: 0.015165369026362896\n",
      "Episode 353, Reward: 2.0\n",
      "Step 460 (693757) @ Episode 354/5000, loss: 0.0213756039738655185\n",
      "Episode 354, Reward: 0.0\n",
      "Step 395 (694153) @ Episode 355/5000, loss: 0.0061123520135879525\n",
      "Episode 355, Reward: 1.0\n",
      "Step 747 (694901) @ Episode 356/5000, loss: 0.0132005577906966215\n",
      "Episode 356, Reward: 8.0\n",
      "Step 408 (695310) @ Episode 357/5000, loss: 0.0153068928048014645\n",
      "Episode 357, Reward: 2.0\n",
      "Step 516 (695827) @ Episode 358/5000, loss: 0.0110710924491286285\n",
      "Episode 358, Reward: 3.0\n",
      "Step 380 (696208) @ Episode 359/5000, loss: 0.0126218888908624656\n",
      "Episode 359, Reward: 3.0\n",
      "Step 328 (696537) @ Episode 360/5000, loss: 0.0161450747400522235\n",
      "Episode 360, Reward: 1.0\n",
      "Step 485 (697023) @ Episode 361/5000, loss: 0.0170081108808517465\n",
      "Episode 361, Reward: 4.0\n",
      "Step 591 (697615) @ Episode 362/5000, loss: 0.0167370513081550645\n",
      "Episode 362, Reward: 5.0\n",
      "Step 453 (698069) @ Episode 363/5000, loss: 0.0061486726626753814\n",
      "Episode 363, Reward: 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 367 (698437) @ Episode 364/5000, loss: 0.0081276874989271165\n",
      "Episode 364, Reward: 4.0\n",
      "Step 392 (698830) @ Episode 365/5000, loss: 0.5594772100448608716\n",
      "Episode 365, Reward: 4.0\n",
      "Step 416 (699247) @ Episode 366/5000, loss: 0.0079654064029455185\n",
      "Episode 366, Reward: 2.0\n",
      "Step 413 (699661) @ Episode 367/5000, loss: 0.0081207714974880225\n",
      "Episode 367, Reward: 3.0\n",
      "Step 566 (700228) @ Episode 368/5000, loss: 0.0085666589438915254\n",
      "Episode 368, Reward: 5.0\n",
      "Step 324 (700553) @ Episode 369/5000, loss: 0.041761044412851334\n",
      "Episode 369, Reward: 2.0\n",
      "Step 338 (700892) @ Episode 370/5000, loss: 0.012551049701869488\n",
      "Episode 370, Reward: 0.0\n",
      "Step 286 (701179) @ Episode 371/5000, loss: 0.0210445765405893335\n",
      "Episode 371, Reward: 2.0\n",
      "Step 727 (701907) @ Episode 372/5000, loss: 0.0209124572575092384\n",
      "Episode 372, Reward: 5.0\n",
      "Step 441 (702349) @ Episode 373/5000, loss: 0.0250997561961412434\n",
      "Episode 373, Reward: 3.0\n",
      "Step 415 (702765) @ Episode 374/5000, loss: 0.014849367551505566\n",
      "Episode 374, Reward: 4.0\n",
      "Step 424 (703190) @ Episode 375/5000, loss: 0.0302518382668495185\n",
      "Episode 375, Reward: 3.0\n",
      "Step 621 (703812) @ Episode 376/5000, loss: 0.0099556576460599955\n",
      "Episode 376, Reward: 4.0\n",
      "Step 550 (704363) @ Episode 377/5000, loss: 0.0174393169581890118\n",
      "Episode 377, Reward: 7.0\n",
      "Step 625 (704989) @ Episode 378/5000, loss: 0.0438097193837165855\n",
      "Episode 378, Reward: 6.0\n",
      "Step 500 (705490) @ Episode 379/5000, loss: 0.0186504721641540535\n",
      "Episode 379, Reward: 4.0\n",
      "Step 403 (705894) @ Episode 380/5000, loss: 0.0269602797925472265\n",
      "Episode 380, Reward: 2.0\n",
      "Step 338 (706233) @ Episode 381/5000, loss: 0.0146429315209388735\n",
      "Episode 381, Reward: 1.0\n",
      "Step 896 (707130) @ Episode 382/5000, loss: 0.0132328923791646964\n",
      "Episode 382, Reward: 12.0\n",
      "Step 600 (707731) @ Episode 383/5000, loss: 0.0098825246095657355\n",
      "Episode 383, Reward: 1.0\n",
      "Step 404 (708136) @ Episode 384/5000, loss: 0.0100188311189413076\n",
      "Episode 384, Reward: 2.0\n",
      "Step 321 (708458) @ Episode 385/5000, loss: 0.008108846843242645\n",
      "Episode 385, Reward: 0.0\n",
      "Step 368 (708827) @ Episode 386/5000, loss: 0.0080065019428730014\n",
      "Episode 386, Reward: 3.0\n",
      "Step 479 (709307) @ Episode 387/5000, loss: 0.4276269376277923685\n",
      "Episode 387, Reward: 6.0\n",
      "Step 441 (709749) @ Episode 388/5000, loss: 0.0206173434853553775\n",
      "Episode 388, Reward: 1.0\n",
      "Step 294 (710044) @ Episode 389/5000, loss: 0.015151703730225563\n",
      "Episode 389, Reward: 1.0\n",
      "Step 437 (710482) @ Episode 390/5000, loss: 0.0087101422250270845\n",
      "Episode 390, Reward: 4.0\n",
      "Step 513 (710996) @ Episode 391/5000, loss: 0.022218253463506725\n",
      "Episode 391, Reward: 3.0\n",
      "Step 567 (711564) @ Episode 392/5000, loss: 0.0178535543382167835\n",
      "Episode 392, Reward: 4.0\n",
      "Step 391 (711956) @ Episode 393/5000, loss: 0.0067621190100908285\n",
      "Episode 393, Reward: 1.0\n",
      "Step 707 (712664) @ Episode 394/5000, loss: 0.0173272453248500825\n",
      "Episode 394, Reward: 3.0\n",
      "Step 406 (713071) @ Episode 395/5000, loss: 0.0108822546899318725\n",
      "Episode 395, Reward: 1.0\n",
      "Step 481 (713553) @ Episode 396/5000, loss: 0.0116238296031951995\n",
      "Episode 396, Reward: 3.0\n",
      "Step 299 (713853) @ Episode 397/5000, loss: 0.0106360856443643575\n",
      "Episode 397, Reward: 1.0\n",
      "Step 665 (714519) @ Episode 398/5000, loss: 0.0170289259403944484\n",
      "Episode 398, Reward: 2.0\n",
      "Step 419 (714939) @ Episode 399/5000, loss: 0.0081401616334915165\n",
      "Episode 399, Reward: 2.0\n",
      "Step 629 (715569) @ Episode 400/5000, loss: 0.0133130047470331225\n",
      "Episode 400, Reward: 5.0\n",
      "Step 333 (715903) @ Episode 401/5000, loss: 0.013974626548588276\n",
      "Episode 401, Reward: 2.0\n",
      "Step 390 (716294) @ Episode 402/5000, loss: 0.0167407765984535225\n",
      "Episode 402, Reward: 4.0\n",
      "Step 306 (716601) @ Episode 403/5000, loss: 0.0078870635479688645\n",
      "Episode 403, Reward: 1.0\n",
      "Step 501 (717103) @ Episode 404/5000, loss: 0.0129248667508363725\n",
      "Episode 404, Reward: 4.0\n",
      "Step 460 (717564) @ Episode 405/5000, loss: 0.0075954832136631015\n",
      "Episode 405, Reward: 3.0\n",
      "Step 505 (718070) @ Episode 406/5000, loss: 0.0156565494835376746\n",
      "Episode 406, Reward: 5.0\n",
      "Step 464 (718535) @ Episode 407/5000, loss: 0.0523937121033668535\n",
      "Episode 407, Reward: 3.0\n",
      "Step 374 (718910) @ Episode 408/5000, loss: 0.0108103407546877865\n",
      "Episode 408, Reward: 1.0\n",
      "Step 366 (719277) @ Episode 409/5000, loss: 0.0047520236112177375\n",
      "Episode 409, Reward: 0.0\n",
      "Step 409 (719687) @ Episode 410/5000, loss: 0.0250988677144050625\n",
      "Episode 410, Reward: 2.0\n",
      "Step 362 (720050) @ Episode 411/5000, loss: 0.0101534221321344384\n",
      "Episode 411, Reward: 2.0\n",
      "Step 547 (720598) @ Episode 412/5000, loss: 0.0090975975617766385\n",
      "Episode 412, Reward: 3.0\n",
      "Step 386 (720985) @ Episode 413/5000, loss: 0.0234120544046163565\n",
      "Episode 413, Reward: 2.0\n",
      "Step 588 (721574) @ Episode 414/5000, loss: 0.0154551519080996515\n",
      "Episode 414, Reward: 4.0\n",
      "Step 449 (722024) @ Episode 415/5000, loss: 0.0089984657242894175\n",
      "Episode 415, Reward: 4.0\n",
      "Step 678 (722703) @ Episode 416/5000, loss: 0.0117852929979562765\n",
      "Episode 416, Reward: 8.0\n",
      "Step 425 (723129) @ Episode 417/5000, loss: 0.0097594372928142555\n",
      "Episode 417, Reward: 3.0\n",
      "Step 479 (723609) @ Episode 418/5000, loss: 0.0126299932599067695\n",
      "Episode 418, Reward: 6.0\n",
      "Step 327 (723937) @ Episode 419/5000, loss: 0.0092297159135341644\n",
      "Episode 419, Reward: 1.0\n",
      "Step 325 (724263) @ Episode 420/5000, loss: 0.0528716556727886245\n",
      "Episode 420, Reward: 1.0\n",
      "Step 288 (724552) @ Episode 421/5000, loss: 0.0059410487301647665\n",
      "Episode 421, Reward: 2.0\n",
      "Step 505 (725058) @ Episode 422/5000, loss: 0.0248299352824687965\n",
      "Episode 422, Reward: 3.0\n",
      "Step 460 (725519) @ Episode 423/5000, loss: 0.0188749916851520545\n",
      "Episode 423, Reward: 3.0\n",
      "Step 460 (725980) @ Episode 424/5000, loss: 0.0165086966007947925\n",
      "Episode 424, Reward: 5.0\n",
      "Step 401 (726382) @ Episode 425/5000, loss: 0.0144622195512056355\n",
      "Episode 425, Reward: 1.0\n",
      "Step 355 (726738) @ Episode 426/5000, loss: 0.0269687939435243625\n",
      "Episode 426, Reward: 1.0\n",
      "Step 453 (727192) @ Episode 427/5000, loss: 0.0106642562896013265\n",
      "Episode 427, Reward: 3.0\n",
      "Step 324 (727517) @ Episode 428/5000, loss: 0.0090711535885930065\n",
      "Episode 428, Reward: 2.0\n",
      "Step 560 (728078) @ Episode 429/5000, loss: 0.0098090618848800665\n",
      "Episode 429, Reward: 5.0\n",
      "Step 534 (728613) @ Episode 430/5000, loss: 0.0085329320281744675\n",
      "Episode 430, Reward: 3.0\n",
      "Step 349 (728963) @ Episode 431/5000, loss: 0.0188001804053783433\n",
      "Episode 431, Reward: 2.0\n",
      "Step 583 (729547) @ Episode 432/5000, loss: 0.0096926605328917555\n",
      "Episode 432, Reward: 5.0\n",
      "Step 432 (729980) @ Episode 433/5000, loss: 0.0288220364600425015\n",
      "Episode 433, Reward: 1.0\n",
      "Step 477 (730458) @ Episode 434/5000, loss: 0.0262612290680408485\n",
      "Episode 434, Reward: 3.0\n",
      "Step 413 (730872) @ Episode 435/5000, loss: 0.0159087106585502625\n",
      "Episode 435, Reward: 2.0\n",
      "Step 354 (731227) @ Episode 436/5000, loss: 0.0293873623013496454\n",
      "Episode 436, Reward: 2.0\n",
      "Step 536 (731764) @ Episode 437/5000, loss: 0.0381831750273704585\n",
      "Episode 437, Reward: 2.0\n",
      "Step 570 (732335) @ Episode 438/5000, loss: 0.0275717116892337896\n",
      "Episode 438, Reward: 6.0\n",
      "Step 290 (732626) @ Episode 439/5000, loss: 0.0116957612335681925\n",
      "Episode 439, Reward: 1.0\n",
      "Step 666 (733293) @ Episode 440/5000, loss: 0.0187668092548847225\n",
      "Episode 440, Reward: 5.0\n",
      "Step 259 (733553) @ Episode 441/5000, loss: 0.0088120847940444955\n",
      "Episode 441, Reward: 1.0\n",
      "Step 469 (734023) @ Episode 442/5000, loss: 0.0064164670184254655\n",
      "Episode 442, Reward: 5.0\n",
      "Step 423 (734447) @ Episode 443/5000, loss: 0.0139258597046136865\n",
      "Episode 443, Reward: 2.0\n",
      "Step 670 (735118) @ Episode 444/5000, loss: 0.0065286024473607545\n",
      "Episode 444, Reward: 6.0\n",
      "Step 486 (735605) @ Episode 445/5000, loss: 0.0106309866532683375\n",
      "Episode 445, Reward: 3.0\n",
      "Step 448 (736054) @ Episode 446/5000, loss: 0.0063130878843367114\n",
      "Episode 446, Reward: 2.0\n",
      "Step 232 (736287) @ Episode 447/5000, loss: 0.0148566896095871935\n",
      "Episode 447, Reward: 1.0\n",
      "Step 282 (736570) @ Episode 448/5000, loss: 0.0416918620467186155\n",
      "Episode 448, Reward: 1.0\n",
      "Step 533 (737104) @ Episode 449/5000, loss: 0.0061392975039780145\n",
      "Episode 449, Reward: 3.0\n",
      "Step 530 (737635) @ Episode 450/5000, loss: 0.0108470311388373375\n",
      "Episode 450, Reward: 5.0\n",
      "Step 313 (737949) @ Episode 451/5000, loss: 0.0135426158085465432\n",
      "Episode 451, Reward: 1.0\n",
      "Step 740 (738690) @ Episode 452/5000, loss: 0.0199689287692308435\n",
      "Episode 452, Reward: 3.0\n",
      "Step 221 (738912) @ Episode 453/5000, loss: 0.0150812771171331415\n",
      "Episode 453, Reward: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 410 (739323) @ Episode 454/5000, loss: 0.0106315175071358685\n",
      "Episode 454, Reward: 2.0\n",
      "Step 523 (739847) @ Episode 455/5000, loss: 0.0090227723121643075\n",
      "Episode 455, Reward: 2.0\n",
      "Step 395 (740243) @ Episode 456/5000, loss: 0.0071770329959690575\n",
      "Episode 456, Reward: 1.0\n",
      "Step 249 (740493) @ Episode 457/5000, loss: 0.012532478198409081\n",
      "Episode 457, Reward: 1.0\n",
      "Step 303 (740797) @ Episode 458/5000, loss: 0.0099153397604823115\n",
      "Episode 458, Reward: 1.0\n",
      "Step 549 (741347) @ Episode 459/5000, loss: 0.0100947860628366476\n",
      "Episode 459, Reward: 5.0\n",
      "Step 307 (741655) @ Episode 460/5000, loss: 0.0084083741530776024\n",
      "Episode 460, Reward: 2.0\n",
      "Step 405 (742061) @ Episode 461/5000, loss: 0.0194065924733877186\n",
      "Episode 461, Reward: 2.0\n",
      "Step 394 (742456) @ Episode 462/5000, loss: 0.1147618070244789164\n",
      "Episode 462, Reward: 3.0\n",
      "Step 448 (742905) @ Episode 463/5000, loss: 0.0403978750109672555\n",
      "Episode 463, Reward: 4.0\n",
      "Step 403 (743309) @ Episode 464/5000, loss: 0.0051942486315965655\n",
      "Episode 464, Reward: 4.0\n",
      "Step 438 (743748) @ Episode 465/5000, loss: 0.0184665136039257055\n",
      "Episode 465, Reward: 2.0\n",
      "Step 342 (744091) @ Episode 466/5000, loss: 0.0341627337038517985\n",
      "Episode 466, Reward: 1.0\n",
      "Step 413 (744505) @ Episode 467/5000, loss: 0.0231512729078531275\n",
      "Episode 467, Reward: 2.0\n",
      "Step 342 (744848) @ Episode 468/5000, loss: 0.0119010377675294885\n",
      "Episode 468, Reward: 2.0\n",
      "Step 531 (745380) @ Episode 469/5000, loss: 0.0076845465227961545\n",
      "Episode 469, Reward: 6.0\n",
      "Step 572 (745953) @ Episode 470/5000, loss: 0.0101368725299835225\n",
      "Episode 470, Reward: 7.0\n",
      "Step 361 (746315) @ Episode 471/5000, loss: 0.0113606834784150125\n",
      "Episode 471, Reward: 2.0\n",
      "Step 402 (746718) @ Episode 472/5000, loss: 0.0084364302456378945\n",
      "Episode 472, Reward: 3.0\n",
      "Step 347 (747066) @ Episode 473/5000, loss: 0.0048809265717864045\n",
      "Episode 473, Reward: 3.0\n",
      "Step 316 (747383) @ Episode 474/5000, loss: 0.0147658959031105045\n",
      "Episode 474, Reward: 2.0\n",
      "Step 222 (747606) @ Episode 475/5000, loss: 0.0188091062009334564\n",
      "Episode 475, Reward: 1.0\n",
      "Step 263 (747870) @ Episode 476/5000, loss: 0.0098409373313188555\n",
      "Episode 476, Reward: 0.0\n",
      "Step 251 (748122) @ Episode 477/5000, loss: 0.0127295861020684245\n",
      "Episode 477, Reward: 0.0\n",
      "Step 321 (748444) @ Episode 478/5000, loss: 0.0108603537082672125\n",
      "Episode 478, Reward: 1.0\n",
      "Step 315 (748760) @ Episode 479/5000, loss: 0.0097493063658475885\n",
      "Episode 479, Reward: 2.0\n",
      "Step 425 (749186) @ Episode 480/5000, loss: 0.0100907608866691595\n",
      "Episode 480, Reward: 3.0\n",
      "Step 475 (749662) @ Episode 481/5000, loss: 0.0211593192070722586\n",
      "Episode 481, Reward: 3.0\n",
      "Step 454 (750117) @ Episode 482/5000, loss: 0.0208805277943611156\n",
      "Episode 482, Reward: 4.0\n",
      "Step 346 (750464) @ Episode 483/5000, loss: 0.0189374387264251745\n",
      "Episode 483, Reward: 2.0\n",
      "Step 320 (750785) @ Episode 484/5000, loss: 0.0106451194733381275\n",
      "Episode 484, Reward: 2.0\n",
      "Step 327 (751113) @ Episode 485/5000, loss: 0.0100108403712511066\n",
      "Episode 485, Reward: 2.0\n",
      "Step 263 (751377) @ Episode 486/5000, loss: 0.0062829377129673965\n",
      "Episode 486, Reward: 1.0\n",
      "Step 411 (751789) @ Episode 487/5000, loss: 0.4476584792137146135\n",
      "Episode 487, Reward: 2.0\n",
      "Step 379 (752169) @ Episode 488/5000, loss: 0.0113828973844647445\n",
      "Episode 488, Reward: 3.0\n",
      "Step 298 (752468) @ Episode 489/5000, loss: 0.0115457233041524895\n",
      "Episode 489, Reward: 1.0\n",
      "Step 374 (752843) @ Episode 490/5000, loss: 0.0137902367860078815\n",
      "Episode 490, Reward: 4.0\n",
      "Step 338 (753182) @ Episode 491/5000, loss: 0.0085023632273077965\n",
      "Episode 491, Reward: 3.0\n",
      "Step 313 (753496) @ Episode 492/5000, loss: 0.0132657447829842575\n",
      "Episode 492, Reward: 1.0\n",
      "Step 671 (754168) @ Episode 493/5000, loss: 0.0162156857550144296\n",
      "Episode 493, Reward: 9.0\n",
      "Step 521 (754690) @ Episode 494/5000, loss: 0.0124641228467226035\n",
      "Episode 494, Reward: 4.0\n",
      "Step 413 (755104) @ Episode 495/5000, loss: 0.0099575622007250795\n",
      "Episode 495, Reward: 2.0\n",
      "Step 359 (755464) @ Episode 496/5000, loss: 0.0083214398473501295\n",
      "Episode 496, Reward: 3.0\n",
      "Step 266 (755731) @ Episode 497/5000, loss: 0.2537029087543487586\n",
      "Episode 497, Reward: 2.0\n",
      "Step 462 (756194) @ Episode 498/5000, loss: 0.021604597568511963\n",
      "Episode 498, Reward: 5.0\n",
      "Step 206 (756401) @ Episode 499/5000, loss: 0.0135046578943729485\n",
      "Episode 499, Reward: 1.0\n",
      "Step 279 (756681) @ Episode 500/5000, loss: 0.0282243378460407265\n",
      "Episode 500, Reward: 2.0\n",
      "Step 374 (757056) @ Episode 501/5000, loss: 0.0096346866339445114\n",
      "Episode 501, Reward: 2.0\n",
      "Step 480 (757537) @ Episode 502/5000, loss: 0.0091852694749832155\n",
      "Episode 502, Reward: 4.0\n",
      "Step 318 (757856) @ Episode 503/5000, loss: 0.0601003244519233775\n",
      "Episode 503, Reward: 1.0\n",
      "Step 219 (758076) @ Episode 504/5000, loss: 0.0036719269119203095\n",
      "Episode 504, Reward: 0.0\n",
      "Step 339 (758416) @ Episode 505/5000, loss: 0.0095577202737331395\n",
      "Episode 505, Reward: 2.0\n",
      "Step 547 (758964) @ Episode 506/5000, loss: 0.0124515257775783545\n",
      "Episode 506, Reward: 4.0\n",
      "Step 504 (759469) @ Episode 507/5000, loss: 0.1756373345851898285\n",
      "Episode 507, Reward: 3.0\n",
      "Step 406 (759876) @ Episode 508/5000, loss: 0.0062417103908956055\n",
      "Episode 508, Reward: 3.0\n",
      "Step 473 (760350) @ Episode 509/5000, loss: 0.0307384356856346135\n",
      "Episode 509, Reward: 5.0\n",
      "Step 312 (760663) @ Episode 510/5000, loss: 0.0059300083667039875\n",
      "Episode 510, Reward: 2.0\n",
      "Step 480 (761144) @ Episode 511/5000, loss: 0.0274891313165426255\n",
      "Episode 511, Reward: 6.0\n",
      "Step 473 (761618) @ Episode 512/5000, loss: 0.0462627857923507775\n",
      "Episode 512, Reward: 5.0\n",
      "Step 246 (761865) @ Episode 513/5000, loss: 0.0181396827101707465\n",
      "Episode 513, Reward: 1.0\n",
      "Step 356 (762222) @ Episode 514/5000, loss: 0.0111326705664396296\n",
      "Episode 514, Reward: 4.0\n",
      "Step 239 (762462) @ Episode 515/5000, loss: 0.0065381862223148355\n",
      "Episode 515, Reward: 1.0\n",
      "Step 478 (762941) @ Episode 516/5000, loss: 0.0072194100357592115\n",
      "Episode 516, Reward: 4.0\n",
      "Step 333 (763275) @ Episode 517/5000, loss: 0.1959046721458435775\n",
      "Episode 517, Reward: 2.0\n",
      "Step 308 (763584) @ Episode 518/5000, loss: 0.0317642241716384955\n",
      "Episode 518, Reward: 2.0\n",
      "Step 296 (763881) @ Episode 519/5000, loss: 0.0084348283708095555\n",
      "Episode 519, Reward: 2.0\n",
      "Step 249 (764131) @ Episode 520/5000, loss: 0.0063673453405499462\n",
      "Episode 520, Reward: 1.0\n",
      "Step 238 (764370) @ Episode 521/5000, loss: 0.0056045195087790495\n",
      "Episode 521, Reward: 1.0\n",
      "Step 328 (764699) @ Episode 522/5000, loss: 0.0075059090740978725\n",
      "Episode 522, Reward: 3.0\n",
      "Step 332 (765032) @ Episode 523/5000, loss: 0.0095820464193820955\n",
      "Episode 523, Reward: 4.0\n",
      "Step 212 (765245) @ Episode 524/5000, loss: 0.0236984267830848784\n",
      "Episode 524, Reward: 1.0\n",
      "Step 267 (765513) @ Episode 525/5000, loss: 0.0594364218413829835\n",
      "Episode 525, Reward: 2.0\n",
      "Step 363 (765877) @ Episode 526/5000, loss: 0.2771978080272674646\n",
      "Episode 526, Reward: 2.0\n",
      "Step 278 (766156) @ Episode 527/5000, loss: 0.0076128593645989895\n",
      "Episode 527, Reward: 1.0\n",
      "Step 185 (766342) @ Episode 528/5000, loss: 0.0112941050902009015\n",
      "Episode 528, Reward: 0.0\n",
      "Step 290 (766633) @ Episode 529/5000, loss: 0.0504410974681377415\n",
      "Episode 529, Reward: 2.0\n",
      "Step 208 (766842) @ Episode 530/5000, loss: 0.0113831609487533575\n",
      "Episode 530, Reward: 1.0\n",
      "Step 248 (767091) @ Episode 531/5000, loss: 0.0165262855589389826\n",
      "Episode 531, Reward: 1.0\n",
      "Step 356 (767448) @ Episode 532/5000, loss: 0.0512044169008731844\n",
      "Episode 532, Reward: 4.0\n",
      "Step 438 (767887) @ Episode 533/5000, loss: 0.0057882056571543226\n",
      "Episode 533, Reward: 4.0\n",
      "Step 386 (768274) @ Episode 534/5000, loss: 0.0073850806802511215\n",
      "Episode 534, Reward: 3.0\n",
      "Step 649 (768924) @ Episode 535/5000, loss: 0.0352670773863792445\n",
      "Episode 535, Reward: 7.0\n",
      "Step 491 (769416) @ Episode 536/5000, loss: 0.0102850403636693955\n",
      "Episode 536, Reward: 4.0\n",
      "Step 232 (769649) @ Episode 537/5000, loss: 0.0063572172075510025\n",
      "Episode 537, Reward: 1.0\n",
      "Step 398 (770048) @ Episode 538/5000, loss: 0.0153738213703036395\n",
      "Episode 538, Reward: 4.0\n",
      "Step 357 (770406) @ Episode 539/5000, loss: 0.1906544864177703922\n",
      "Episode 539, Reward: 2.0\n",
      "Step 263 (770670) @ Episode 540/5000, loss: 0.0083403270691633226\n",
      "Episode 540, Reward: 2.0\n",
      "Step 511 (771182) @ Episode 541/5000, loss: 0.0110436379909515385\n",
      "Episode 541, Reward: 4.0\n",
      "Step 283 (771466) @ Episode 542/5000, loss: 0.0233662780374288565\n",
      "Episode 542, Reward: 2.0\n",
      "Step 438 (771905) @ Episode 543/5000, loss: 0.0095769241452217145\n",
      "Episode 543, Reward: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 230 (772136) @ Episode 544/5000, loss: 0.0107081308960914615\n",
      "Episode 544, Reward: 1.0\n",
      "Step 419 (772556) @ Episode 545/5000, loss: 0.1240744888782501224\n",
      "Episode 545, Reward: 4.0\n",
      "Step 177 (772734) @ Episode 546/5000, loss: 0.013065954670310028\n",
      "Episode 546, Reward: 0.0\n",
      "Step 161 (772896) @ Episode 547/5000, loss: 0.0123016797006130225\n",
      "Episode 547, Reward: 0.0\n",
      "Step 268 (773165) @ Episode 548/5000, loss: 0.0051203146576881415\n",
      "Episode 548, Reward: 2.0\n",
      "Step 316 (773482) @ Episode 549/5000, loss: 0.0090865353122353555\n",
      "Episode 549, Reward: 2.0\n",
      "Step 209 (773692) @ Episode 550/5000, loss: 0.0191698148846626284\n",
      "Episode 550, Reward: 1.0\n",
      "Step 295 (773988) @ Episode 551/5000, loss: 0.0626999884843826375\n",
      "Episode 551, Reward: 3.0\n",
      "Step 490 (774479) @ Episode 552/5000, loss: 0.0133648253977298745\n",
      "Episode 552, Reward: 5.0\n",
      "Step 178 (774658) @ Episode 553/5000, loss: 0.014660583809018135\n",
      "Episode 553, Reward: 0.0\n",
      "Step 268 (774927) @ Episode 554/5000, loss: 0.0135845802724361425\n",
      "Episode 554, Reward: 1.0\n",
      "Step 232 (775160) @ Episode 555/5000, loss: 0.0084226410835981374\n",
      "Episode 555, Reward: 1.0\n",
      "Step 264 (775425) @ Episode 556/5000, loss: 0.0447054281830787665\n",
      "Episode 556, Reward: 2.0\n",
      "Step 242 (775668) @ Episode 557/5000, loss: 0.5321652889251709565\n",
      "Episode 557, Reward: 1.0\n",
      "Step 394 (776063) @ Episode 558/5000, loss: 0.0091567896306514745\n",
      "Episode 558, Reward: 4.0\n",
      "Step 370 (776434) @ Episode 559/5000, loss: 0.0213181916624307635\n",
      "Episode 559, Reward: 4.0\n",
      "Step 333 (776768) @ Episode 560/5000, loss: 0.0091690449044108395\n",
      "Episode 560, Reward: 3.0\n",
      "Step 250 (777019) @ Episode 561/5000, loss: 0.0088906399905681615\n",
      "Episode 561, Reward: 2.0\n",
      "Step 417 (777437) @ Episode 562/5000, loss: 0.0181415416300296864\n",
      "Episode 562, Reward: 4.0\n",
      "Step 298 (777736) @ Episode 563/5000, loss: 0.0088543808087706573\n",
      "Episode 563, Reward: 2.0\n",
      "Step 346 (778083) @ Episode 564/5000, loss: 0.0157528501003980645\n",
      "Episode 564, Reward: 2.0\n",
      "Step 266 (778350) @ Episode 565/5000, loss: 0.0077841607853770265\n",
      "Episode 565, Reward: 2.0\n",
      "Step 295 (778646) @ Episode 566/5000, loss: 0.0078976312652230264\n",
      "Episode 566, Reward: 2.0\n",
      "Step 213 (778860) @ Episode 567/5000, loss: 0.0059989169239997865\n",
      "Episode 567, Reward: 1.0\n",
      "Step 375 (779236) @ Episode 568/5000, loss: 0.0077835340052843095\n",
      "Episode 568, Reward: 3.0\n",
      "Step 383 (779620) @ Episode 569/5000, loss: 0.0174456275999546054\n",
      "Episode 569, Reward: 4.0\n",
      "Step 168 (779789) @ Episode 570/5000, loss: 0.0067652203142642975\n",
      "Episode 570, Reward: 0.0\n",
      "Step 266 (780056) @ Episode 571/5000, loss: 0.0068929097615182445\n",
      "Episode 571, Reward: 2.0\n",
      "Step 375 (780432) @ Episode 572/5000, loss: 0.0352803692221641545\n",
      "Episode 572, Reward: 4.0\n",
      "Step 331 (780764) @ Episode 573/5000, loss: 0.0245596468448638915\n",
      "Episode 573, Reward: 3.0\n",
      "Step 325 (781090) @ Episode 574/5000, loss: 0.0233854725956916826\n",
      "Episode 574, Reward: 3.0\n",
      "Step 422 (781513) @ Episode 575/5000, loss: 0.0165094994008541135\n",
      "Episode 575, Reward: 3.0\n",
      "Step 367 (781881) @ Episode 576/5000, loss: 0.0423701107501983645\n",
      "Episode 576, Reward: 4.0\n",
      "Step 255 (782137) @ Episode 577/5000, loss: 0.0251775905489921574\n",
      "Episode 577, Reward: 2.0\n",
      "Step 386 (782524) @ Episode 578/5000, loss: 0.0096036642789840735\n",
      "Episode 578, Reward: 4.0\n",
      "Step 272 (782797) @ Episode 579/5000, loss: 0.0093654487282037735\n",
      "Episode 579, Reward: 2.0\n",
      "Step 526 (783324) @ Episode 580/5000, loss: 0.0093421125784516335\n",
      "Episode 580, Reward: 7.0\n",
      "Step 279 (783604) @ Episode 581/5000, loss: 0.0062514999881386765\n",
      "Episode 581, Reward: 2.0\n",
      "Step 198 (783803) @ Episode 582/5000, loss: 0.0070192171260714535\n",
      "Episode 582, Reward: 1.0\n",
      "Step 438 (784242) @ Episode 583/5000, loss: 0.0129532590508461535\n",
      "Episode 583, Reward: 4.0\n",
      "Step 279 (784522) @ Episode 584/5000, loss: 0.0123196206986904145\n",
      "Episode 584, Reward: 2.0\n",
      "Step 228 (784751) @ Episode 585/5000, loss: 0.0171492509543895725\n",
      "Episode 585, Reward: 1.0\n",
      "Step 248 (785000) @ Episode 586/5000, loss: 0.0075705302879214295\n",
      "Episode 586, Reward: 2.0\n",
      "Step 549 (785550) @ Episode 587/5000, loss: 0.0079396720975637445\n",
      "Episode 587, Reward: 7.0\n",
      "Step 234 (785785) @ Episode 588/5000, loss: 0.0104018934071064774\n",
      "Episode 588, Reward: 2.0\n",
      "Step 373 (786159) @ Episode 589/5000, loss: 0.0149259250611066825\n",
      "Episode 589, Reward: 3.0\n",
      "Step 231 (786391) @ Episode 590/5000, loss: 0.0075143827125430115\n",
      "Episode 590, Reward: 1.0\n",
      "Step 337 (786729) @ Episode 591/5000, loss: 0.0132696144282817846\n",
      "Episode 591, Reward: 3.0\n",
      "Step 214 (786944) @ Episode 592/5000, loss: 0.0106363026425242425\n",
      "Episode 592, Reward: 1.0\n",
      "Step 256 (787201) @ Episode 593/5000, loss: 0.0119859892874956135\n",
      "Episode 593, Reward: 2.0\n",
      "Step 197 (787399) @ Episode 594/5000, loss: 0.0070784199051558972\n",
      "Episode 594, Reward: 1.0\n",
      "Step 224 (787624) @ Episode 595/5000, loss: 0.0104696024209260945\n",
      "Episode 595, Reward: 1.0\n",
      "Step 221 (787846) @ Episode 596/5000, loss: 0.0089271329343318946\n",
      "Episode 596, Reward: 1.0\n",
      "Step 330 (788177) @ Episode 597/5000, loss: 0.0059959464706480564\n",
      "Episode 597, Reward: 3.0\n",
      "Step 268 (788446) @ Episode 598/5000, loss: 0.0077021857723593713\n",
      "Episode 598, Reward: 2.0\n",
      "Step 339 (788786) @ Episode 599/5000, loss: 0.0130238886922597895\n",
      "Episode 599, Reward: 3.0\n",
      "Step 203 (788990) @ Episode 600/5000, loss: 0.3444994390010834434\n",
      "Episode 600, Reward: 1.0\n",
      "Step 269 (789260) @ Episode 601/5000, loss: 0.0156756415963172955\n",
      "Episode 601, Reward: 2.0\n",
      "Step 223 (789484) @ Episode 602/5000, loss: 0.0076979361474514015\n",
      "Episode 602, Reward: 1.0\n",
      "Step 315 (789800) @ Episode 603/5000, loss: 0.0111802220344543465\n",
      "Episode 603, Reward: 3.0\n",
      "Step 198 (789999) @ Episode 604/5000, loss: 0.0054975049570202836\n",
      "Episode 604, Reward: 1.0\n",
      "Step 339 (790339) @ Episode 605/5000, loss: 0.0135333612561225895\n",
      "Episode 605, Reward: 4.0\n",
      "Step 212 (790552) @ Episode 606/5000, loss: 0.0092305187135934835\n",
      "Episode 606, Reward: 1.0\n",
      "Step 360 (790913) @ Episode 607/5000, loss: 0.4320404827594757765\n",
      "Episode 607, Reward: 3.0\n",
      "Step 227 (791141) @ Episode 608/5000, loss: 0.0110532930120825775\n",
      "Episode 608, Reward: 1.0\n",
      "Step 516 (791658) @ Episode 609/5000, loss: 0.0178100094199180644\n",
      "Episode 609, Reward: 7.0\n",
      "Step 369 (792028) @ Episode 610/5000, loss: 0.0346820130944252235\n",
      "Episode 610, Reward: 5.0\n",
      "Step 302 (792331) @ Episode 611/5000, loss: 0.0233697276562452335\n",
      "Episode 611, Reward: 3.0\n",
      "Step 164 (792496) @ Episode 612/5000, loss: 0.006979638244956732\n",
      "Episode 612, Reward: 0.0\n",
      "Step 372 (792869) @ Episode 613/5000, loss: 0.0071137966588139535\n",
      "Episode 613, Reward: 8.0\n",
      "Step 200 (793070) @ Episode 614/5000, loss: 0.0110463500022888184\n",
      "Episode 614, Reward: 1.0\n",
      "Step 219 (793290) @ Episode 615/5000, loss: 0.0135233271867036825\n",
      "Episode 615, Reward: 1.0\n",
      "Step 220 (793511) @ Episode 616/5000, loss: 0.0214639343321323475\n",
      "Episode 616, Reward: 1.0\n",
      "Step 234 (793746) @ Episode 617/5000, loss: 0.0157221648842096335\n",
      "Episode 617, Reward: 1.0\n",
      "Step 387 (794134) @ Episode 618/5000, loss: 0.0102326199412345895\n",
      "Episode 618, Reward: 4.0\n",
      "Step 197 (794332) @ Episode 619/5000, loss: 0.0097697414457798175\n",
      "Episode 619, Reward: 1.0\n",
      "Step 222 (794555) @ Episode 620/5000, loss: 0.0108742946758866316\n",
      "Episode 620, Reward: 1.0\n",
      "Step 214 (794770) @ Episode 621/5000, loss: 0.0131746977567672735\n",
      "Episode 621, Reward: 1.0\n",
      "Step 298 (795069) @ Episode 622/5000, loss: 0.0195103362202644355\n",
      "Episode 622, Reward: 3.0\n",
      "Step 267 (795337) @ Episode 623/5000, loss: 0.0093450034037232465\n",
      "Episode 623, Reward: 2.0\n",
      "Step 223 (795561) @ Episode 624/5000, loss: 0.0122715244069695475\n",
      "Episode 624, Reward: 1.0\n",
      "Step 387 (795949) @ Episode 625/5000, loss: 0.0185801386833190925\n",
      "Episode 625, Reward: 4.0\n",
      "Step 198 (796148) @ Episode 626/5000, loss: 0.0113131608814001085\n",
      "Episode 626, Reward: 1.0\n",
      "Step 211 (796360) @ Episode 627/5000, loss: 0.0119471177458763125\n",
      "Episode 627, Reward: 1.0\n",
      "Step 261 (796622) @ Episode 628/5000, loss: 0.0189989600330591265\n",
      "Episode 628, Reward: 2.0\n",
      "Step 263 (796886) @ Episode 629/5000, loss: 0.0122207030653953555\n",
      "Episode 629, Reward: 2.0\n",
      "Step 468 (797355) @ Episode 630/5000, loss: 0.0074045560322701935\n",
      "Episode 630, Reward: 5.0\n",
      "Step 312 (797668) @ Episode 631/5000, loss: 0.0102900955826044085\n",
      "Episode 631, Reward: 3.0\n",
      "Step 405 (798074) @ Episode 632/5000, loss: 0.0263014379888772965\n",
      "Episode 632, Reward: 5.0\n",
      "Step 292 (798367) @ Episode 633/5000, loss: 0.0149203315377235415\n",
      "Episode 633, Reward: 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 381 (798749) @ Episode 634/5000, loss: 0.0079557355493307115\n",
      "Episode 634, Reward: 4.0\n",
      "Step 238 (798988) @ Episode 635/5000, loss: 0.0073031042702496054\n",
      "Episode 635, Reward: 2.0\n",
      "Step 380 (799369) @ Episode 636/5000, loss: 0.0135032236576080325\n",
      "Episode 636, Reward: 4.0\n",
      "Step 287 (799657) @ Episode 637/5000, loss: 0.0100009683519601825\n",
      "Episode 637, Reward: 2.0\n",
      "Step 300 (799958) @ Episode 638/5000, loss: 0.0396181046962738045\n",
      "Episode 638, Reward: 3.0\n",
      "Step 199 (800158) @ Episode 639/5000, loss: 0.0087552117183804516\n",
      "Episode 639, Reward: 1.0\n",
      "Step 387 (800546) @ Episode 640/5000, loss: 0.0093411002308130265\n",
      "Episode 640, Reward: 4.0\n",
      "Step 195 (800742) @ Episode 641/5000, loss: 0.294731765985488915\n",
      "Episode 641, Reward: 0.0\n",
      "Step 346 (801089) @ Episode 642/5000, loss: 0.0063033560290932655\n",
      "Episode 642, Reward: 1.0\n",
      "Step 303 (801393) @ Episode 643/5000, loss: 0.0079282186925411226\n",
      "Episode 643, Reward: 2.0\n",
      "Step 432 (801826) @ Episode 644/5000, loss: 0.0085461838170886045\n",
      "Episode 644, Reward: 4.0\n",
      "Step 204 (802031) @ Episode 645/5000, loss: 0.0201641656458377845\n",
      "Episode 645, Reward: 1.0\n",
      "Step 331 (802363) @ Episode 646/5000, loss: 0.0101944683119654665\n",
      "Episode 646, Reward: 3.0\n",
      "Step 345 (802709) @ Episode 647/5000, loss: 0.0119747612625360497\n",
      "Episode 647, Reward: 4.0\n",
      "Step 368 (803078) @ Episode 648/5000, loss: 0.0099978931248188026\n",
      "Episode 648, Reward: 3.0\n",
      "Step 232 (803311) @ Episode 649/5000, loss: 0.0056055570021271706\n",
      "Episode 649, Reward: 1.0\n",
      "Step 458 (803770) @ Episode 650/5000, loss: 0.0108500458300113685\n",
      "Episode 650, Reward: 4.0\n",
      "Step 219 (803990) @ Episode 651/5000, loss: 0.0051636109128594414\n",
      "Episode 651, Reward: 1.0\n",
      "Step 221 (804212) @ Episode 652/5000, loss: 0.0062117213383316995\n",
      "Episode 652, Reward: 1.0\n",
      "Step 173 (804386) @ Episode 653/5000, loss: 0.0068428022786974915\n",
      "Episode 653, Reward: 0.0\n",
      "Step 356 (804743) @ Episode 654/5000, loss: 0.0264796670526266165\n",
      "Episode 654, Reward: 3.0\n",
      "Step 228 (804972) @ Episode 655/5000, loss: 0.0228364281356334775\n",
      "Episode 655, Reward: 1.0\n",
      "Step 391 (805364) @ Episode 656/5000, loss: 0.0074292737990617755\n",
      "Episode 656, Reward: 3.0\n",
      "Step 485 (805850) @ Episode 657/5000, loss: 0.0087044443935155875\n",
      "Episode 657, Reward: 4.0\n",
      "Step 176 (806027) @ Episode 658/5000, loss: 0.0127044655382633214\n",
      "Episode 658, Reward: 0.0\n",
      "Step 311 (806339) @ Episode 659/5000, loss: 0.0114337466657161715\n",
      "Episode 659, Reward: 2.0\n",
      "Step 476 (806816) @ Episode 660/5000, loss: 0.0153737459331750874\n",
      "Episode 660, Reward: 6.0\n",
      "Step 241 (807058) @ Episode 661/5000, loss: 0.0083313602954149255\n",
      "Episode 661, Reward: 2.0\n",
      "Step 266 (807325) @ Episode 662/5000, loss: 0.0104992035776376724\n",
      "Episode 662, Reward: 2.0\n",
      "Step 211 (807537) @ Episode 663/5000, loss: 0.0112366788089275368\n",
      "Episode 663, Reward: 1.0\n",
      "Step 228 (807766) @ Episode 664/5000, loss: 0.0085010137408971795\n",
      "Episode 664, Reward: 1.0\n",
      "Step 202 (807969) @ Episode 665/5000, loss: 0.0263713560998439815\n",
      "Episode 665, Reward: 1.0\n",
      "Step 268 (808238) @ Episode 666/5000, loss: 0.0124057363718748145\n",
      "Episode 666, Reward: 2.0\n",
      "Step 346 (808585) @ Episode 667/5000, loss: 0.0068181119859218635\n",
      "Episode 667, Reward: 2.0\n",
      "Step 317 (808903) @ Episode 668/5000, loss: 0.0062700659036636355\n",
      "Episode 668, Reward: 3.0\n",
      "Step 419 (809323) @ Episode 669/5000, loss: 0.0737894698977470435\n",
      "Episode 669, Reward: 8.0\n",
      "Step 457 (809781) @ Episode 670/5000, loss: 0.0090863965451717385\n",
      "Episode 670, Reward: 6.0\n",
      "Step 339 (810121) @ Episode 671/5000, loss: 0.0089244320988655095\n",
      "Episode 671, Reward: 3.0\n",
      "Step 367 (810489) @ Episode 672/5000, loss: 0.0161541271954774866\n",
      "Episode 672, Reward: 4.0\n",
      "Step 286 (810776) @ Episode 673/5000, loss: 0.0115260286256670956\n",
      "Episode 673, Reward: 2.0\n",
      "Step 203 (810980) @ Episode 674/5000, loss: 0.0109837967902421955\n",
      "Episode 674, Reward: 1.0\n",
      "Step 295 (811276) @ Episode 675/5000, loss: 0.011247267015278348\n",
      "Episode 675, Reward: 2.0\n",
      "Step 285 (811562) @ Episode 676/5000, loss: 0.0101227760314941485\n",
      "Episode 676, Reward: 3.0\n",
      "Step 278 (811841) @ Episode 677/5000, loss: 0.0090845972299575815\n",
      "Episode 677, Reward: 2.0\n",
      "Step 308 (812150) @ Episode 678/5000, loss: 0.0130419060587883735\n",
      "Episode 678, Reward: 2.0\n",
      "Step 368 (812519) @ Episode 679/5000, loss: 0.0109896948561072355\n",
      "Episode 679, Reward: 3.0\n",
      "Step 234 (812754) @ Episode 680/5000, loss: 0.0139693990349769645\n",
      "Episode 680, Reward: 1.0\n",
      "Step 306 (813061) @ Episode 681/5000, loss: 0.0081246085464954386\n",
      "Episode 681, Reward: 3.0\n",
      "Step 405 (813467) @ Episode 682/5000, loss: 0.0088926423341035845\n",
      "Episode 682, Reward: 3.0\n",
      "Step 302 (813770) @ Episode 683/5000, loss: 0.0370091423392295845\n",
      "Episode 683, Reward: 3.0\n",
      "Step 350 (814121) @ Episode 684/5000, loss: 0.0136538008227944376\n",
      "Episode 684, Reward: 4.0\n",
      "Step 306 (814428) @ Episode 685/5000, loss: 0.0119112320244312293\n",
      "Episode 685, Reward: 2.0\n",
      "Step 376 (814805) @ Episode 686/5000, loss: 0.0134501066058874135\n",
      "Episode 686, Reward: 4.0\n",
      "Step 282 (815088) @ Episode 687/5000, loss: 0.0079072657972574235\n",
      "Episode 687, Reward: 2.0\n",
      "Step 267 (815356) @ Episode 688/5000, loss: 0.0158369373530149465\n",
      "Episode 688, Reward: 2.0\n",
      "Step 526 (815883) @ Episode 689/5000, loss: 0.0131809487938880925\n",
      "Episode 689, Reward: 6.0\n",
      "Step 330 (816214) @ Episode 690/5000, loss: 0.0178299210965633445\n",
      "Episode 690, Reward: 3.0\n",
      "Step 330 (816545) @ Episode 691/5000, loss: 0.0102641787379980096\n",
      "Episode 691, Reward: 3.0\n",
      "Step 332 (816878) @ Episode 692/5000, loss: 0.0065827779471874245\n",
      "Episode 692, Reward: 3.0\n",
      "Step 495 (817374) @ Episode 693/5000, loss: 0.0151873733848333363\n",
      "Episode 693, Reward: 5.0\n",
      "Step 347 (817722) @ Episode 694/5000, loss: 0.0086170295253396035\n",
      "Episode 694, Reward: 4.0\n",
      "Step 311 (818034) @ Episode 695/5000, loss: 0.2345236092805862496\n",
      "Episode 695, Reward: 3.0\n",
      "Step 261 (818296) @ Episode 696/5000, loss: 0.0153710804879665375\n",
      "Episode 696, Reward: 2.0\n",
      "Step 421 (818718) @ Episode 697/5000, loss: 0.0054729543626308445\n",
      "Episode 697, Reward: 4.0\n",
      "Step 176 (818895) @ Episode 698/5000, loss: 0.0268985610455274585\n",
      "Episode 698, Reward: 0.0\n",
      "Step 252 (819148) @ Episode 699/5000, loss: 0.0109502095729112635\n",
      "Episode 699, Reward: 2.0\n",
      "Step 277 (819426) @ Episode 700/5000, loss: 0.0111603895202279095\n",
      "Episode 700, Reward: 2.0\n",
      "Step 262 (819689) @ Episode 701/5000, loss: 0.0143326725810766225\n",
      "Episode 701, Reward: 1.0\n",
      "Step 453 (820143) @ Episode 702/5000, loss: 0.0087042711675167085\n",
      "Episode 702, Reward: 5.0\n",
      "Step 162 (820306) @ Episode 703/5000, loss: 0.0063385423272848135\n",
      "Episode 703, Reward: 0.0\n",
      "Step 276 (820583) @ Episode 704/5000, loss: 0.0077859102748334414\n",
      "Episode 704, Reward: 2.0\n",
      "Step 223 (820807) @ Episode 705/5000, loss: 0.0443554893136024554\n",
      "Episode 705, Reward: 1.0\n",
      "Step 223 (821031) @ Episode 706/5000, loss: 0.0050764307379722595\n",
      "Episode 706, Reward: 1.0\n",
      "Step 364 (821396) @ Episode 707/5000, loss: 0.0253969635814428335\n",
      "Episode 707, Reward: 3.0\n",
      "Step 253 (821650) @ Episode 708/5000, loss: 0.0074164266698062425\n",
      "Episode 708, Reward: 1.0\n",
      "Step 242 (821893) @ Episode 709/5000, loss: 0.0114707499742507935\n",
      "Episode 709, Reward: 2.0\n",
      "Step 459 (822353) @ Episode 710/5000, loss: 0.0063923317939043045\n",
      "Episode 710, Reward: 6.0\n",
      "Step 293 (822647) @ Episode 711/5000, loss: 0.0097620328888297085\n",
      "Episode 711, Reward: 3.0\n",
      "Step 401 (823049) @ Episode 712/5000, loss: 0.0112708611413836485\n",
      "Episode 712, Reward: 4.0\n",
      "Step 363 (823413) @ Episode 713/5000, loss: 0.0098676811903715137\n",
      "Episode 713, Reward: 4.0\n",
      "Step 242 (823656) @ Episode 714/5000, loss: 0.0448808073997497565\n",
      "Episode 714, Reward: 1.0\n",
      "Step 172 (823829) @ Episode 715/5000, loss: 0.0112307965755462654\n",
      "Episode 715, Reward: 0.0\n",
      "Step 471 (824301) @ Episode 716/5000, loss: 0.0062805879861116415\n",
      "Episode 716, Reward: 6.0\n",
      "Step 175 (824477) @ Episode 717/5000, loss: 0.0068143988028168686\n",
      "Episode 717, Reward: 0.0\n",
      "Step 188 (824666) @ Episode 718/5000, loss: 0.5592060089111328385\n",
      "Episode 718, Reward: 0.0\n",
      "Step 243 (824910) @ Episode 719/5000, loss: 0.0149262659251689915\n",
      "Episode 719, Reward: 1.0\n",
      "Step 330 (825241) @ Episode 720/5000, loss: 0.0103257736191153535\n",
      "Episode 720, Reward: 3.0\n",
      "Step 340 (825582) @ Episode 721/5000, loss: 0.0075058611109852796\n",
      "Episode 721, Reward: 4.0\n",
      "Step 167 (825750) @ Episode 722/5000, loss: 0.0110509339720010764\n",
      "Episode 722, Reward: 0.0\n",
      "Step 454 (826205) @ Episode 723/5000, loss: 0.0126837845891714154\n",
      "Episode 723, Reward: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 184 (826390) @ Episode 724/5000, loss: 0.0066099595278501514\n",
      "Episode 724, Reward: 0.0\n",
      "Step 275 (826666) @ Episode 725/5000, loss: 0.0106710968539118772\n",
      "Episode 725, Reward: 2.0\n",
      "Step 247 (826914) @ Episode 726/5000, loss: 0.0345377586781978625\n",
      "Episode 726, Reward: 2.0\n",
      "Step 465 (827380) @ Episode 727/5000, loss: 0.0097657013684511185\n",
      "Episode 727, Reward: 3.0\n",
      "Step 326 (827707) @ Episode 728/5000, loss: 0.0123656606301665375\n",
      "Episode 728, Reward: 3.0\n",
      "Step 169 (827877) @ Episode 729/5000, loss: 0.0115889627486467365\n",
      "Episode 729, Reward: 0.0\n",
      "Step 317 (828195) @ Episode 730/5000, loss: 0.0379930622875690464\n",
      "Episode 730, Reward: 3.0\n",
      "Step 159 (828355) @ Episode 731/5000, loss: 0.016204245388507843\n",
      "Episode 731, Reward: 0.0\n",
      "Step 380 (828736) @ Episode 732/5000, loss: 0.0056877844035625465\n",
      "Episode 732, Reward: 4.0\n",
      "Step 281 (829018) @ Episode 733/5000, loss: 0.0194552931934595117\n",
      "Episode 733, Reward: 3.0\n",
      "Step 356 (829375) @ Episode 734/5000, loss: 0.0070737283676862724\n",
      "Episode 734, Reward: 3.0\n",
      "Step 195 (829571) @ Episode 735/5000, loss: 0.0113213919103145645\n",
      "Episode 735, Reward: 0.0\n",
      "Step 174 (829746) @ Episode 736/5000, loss: 0.0169811043888330465\n",
      "Episode 736, Reward: 0.0\n",
      "Step 331 (830078) @ Episode 737/5000, loss: 0.0179385803639888765\n",
      "Episode 737, Reward: 2.0\n",
      "Step 303 (830382) @ Episode 738/5000, loss: 0.0371429398655891436\n",
      "Episode 738, Reward: 3.0\n",
      "Step 225 (830608) @ Episode 739/5000, loss: 0.0242463797330856325\n",
      "Episode 739, Reward: 1.0\n",
      "Step 345 (830954) @ Episode 740/5000, loss: 0.0061815367080271246\n",
      "Episode 740, Reward: 3.0\n",
      "Step 293 (831248) @ Episode 741/5000, loss: 0.0126608619466423995\n",
      "Episode 741, Reward: 2.0\n",
      "Step 366 (831615) @ Episode 742/5000, loss: 0.0066678375005722055\n",
      "Episode 742, Reward: 3.0\n",
      "Step 213 (831829) @ Episode 743/5000, loss: 0.0142451161518692975\n",
      "Episode 743, Reward: 1.0\n",
      "Step 217 (832047) @ Episode 744/5000, loss: 0.0170234031975269325\n",
      "Episode 744, Reward: 1.0\n",
      "Step 341 (832389) @ Episode 745/5000, loss: 0.0094924746081233025\n",
      "Episode 745, Reward: 3.0\n",
      "Step 282 (832672) @ Episode 746/5000, loss: 0.0146660367026925095\n",
      "Episode 746, Reward: 2.0\n",
      "Step 275 (832948) @ Episode 747/5000, loss: 0.0192694514989852956\n",
      "Episode 747, Reward: 2.0\n",
      "Step 231 (833180) @ Episode 748/5000, loss: 0.0109391510486602785\n",
      "Episode 748, Reward: 1.0\n",
      "Step 416 (833597) @ Episode 749/5000, loss: 0.0167923010885715545\n",
      "Episode 749, Reward: 4.0\n",
      "Step 187 (833785) @ Episode 750/5000, loss: 0.013822881504893303\n",
      "Episode 750, Reward: 0.0\n",
      "Step 208 (833994) @ Episode 751/5000, loss: 0.0081902043893933375\n",
      "Episode 751, Reward: 1.0\n",
      "Step 416 (834411) @ Episode 752/5000, loss: 0.0102700237184762955\n",
      "Episode 752, Reward: 5.0\n",
      "Step 253 (834665) @ Episode 753/5000, loss: 0.4447300136089325263\n",
      "Episode 753, Reward: 2.0\n",
      "Step 175 (834841) @ Episode 754/5000, loss: 0.005893325433135033\n",
      "Episode 754, Reward: 0.0\n",
      "Step 323 (835165) @ Episode 755/5000, loss: 0.0089859478175640185\n",
      "Episode 755, Reward: 3.0\n",
      "Step 334 (835500) @ Episode 756/5000, loss: 0.0230527818202972457\n",
      "Episode 756, Reward: 3.0\n",
      "Step 165 (835666) @ Episode 757/5000, loss: 0.0327862128615379375\n",
      "Episode 757, Reward: 0.0\n",
      "Step 355 (836022) @ Episode 758/5000, loss: 0.0081673422828316696\n",
      "Episode 758, Reward: 3.0\n",
      "Step 392 (836415) @ Episode 759/5000, loss: 0.0081844665110111245\n",
      "Episode 759, Reward: 4.0\n",
      "Step 358 (836774) @ Episode 760/5000, loss: 0.0116912117227911954\n",
      "Episode 760, Reward: 4.0\n",
      "Step 441 (837216) @ Episode 761/5000, loss: 0.0101738525554537775\n",
      "Episode 761, Reward: 4.0\n",
      "Step 240 (837457) @ Episode 762/5000, loss: 0.0080331237986683855\n",
      "Episode 762, Reward: 2.0\n",
      "Step 172 (837630) @ Episode 763/5000, loss: 0.0074729137122631075\n",
      "Episode 763, Reward: 0.0\n",
      "Step 243 (837874) @ Episode 764/5000, loss: 0.0155428471043705946\n",
      "Episode 764, Reward: 2.0\n",
      "Step 571 (838446) @ Episode 765/5000, loss: 0.0071193417534232145\n",
      "Episode 765, Reward: 7.0\n",
      "Step 416 (838863) @ Episode 766/5000, loss: 0.0069747087545692925\n",
      "Episode 766, Reward: 4.0\n",
      "Step 300 (839164) @ Episode 767/5000, loss: 0.0061224317178130155\n",
      "Episode 767, Reward: 2.0\n",
      "Step 331 (839496) @ Episode 768/5000, loss: 0.0114982780069112785\n",
      "Episode 768, Reward: 2.0\n",
      "Step 480 (839977) @ Episode 769/5000, loss: 0.0124951470643281945\n",
      "Episode 769, Reward: 4.0\n",
      "Step 218 (840196) @ Episode 770/5000, loss: 0.0175566338002681735\n",
      "Episode 770, Reward: 1.0\n",
      "Step 286 (840483) @ Episode 771/5000, loss: 0.0098879486322402954\n",
      "Episode 771, Reward: 2.0\n",
      "Step 502 (840986) @ Episode 772/5000, loss: 0.0155762480571866045\n",
      "Episode 772, Reward: 5.0\n",
      "Step 213 (841200) @ Episode 773/5000, loss: 0.0104880183935165484\n",
      "Episode 773, Reward: 1.0\n",
      "Step 245 (841446) @ Episode 774/5000, loss: 0.0481033474206924445\n",
      "Episode 774, Reward: 1.0\n",
      "Step 372 (841819) @ Episode 775/5000, loss: 0.0121351145207881935\n",
      "Episode 775, Reward: 3.0\n",
      "Step 265 (842085) @ Episode 776/5000, loss: 0.0188928730785846725\n",
      "Episode 776, Reward: 2.0\n",
      "Step 194 (842280) @ Episode 777/5000, loss: 0.0115453014150261885\n",
      "Episode 777, Reward: 0.0\n",
      "Step 507 (842788) @ Episode 778/5000, loss: 0.0081488369032740685\n",
      "Episode 778, Reward: 6.0\n",
      "Step 379 (843168) @ Episode 779/5000, loss: 0.0072141317650675778\n",
      "Episode 779, Reward: 3.0\n",
      "Step 214 (843383) @ Episode 780/5000, loss: 0.014572534710168839\n",
      "Episode 780, Reward: 0.0\n",
      "Step 645 (844029) @ Episode 781/5000, loss: 0.0069743553176522255\n",
      "Episode 781, Reward: 6.0\n",
      "Step 338 (844368) @ Episode 782/5000, loss: 0.0492620840668678376\n",
      "Episode 782, Reward: 4.0\n",
      "Step 427 (844796) @ Episode 783/5000, loss: 0.1441889107227325425\n",
      "Episode 783, Reward: 4.0\n",
      "Step 262 (845059) @ Episode 784/5000, loss: 0.0256147384643554795\n",
      "Episode 784, Reward: 1.0\n",
      "Step 385 (845445) @ Episode 785/5000, loss: 0.0142084974795579915\n",
      "Episode 785, Reward: 4.0\n",
      "Step 398 (845844) @ Episode 786/5000, loss: 0.0118859857320785523\n",
      "Episode 786, Reward: 4.0\n",
      "Step 394 (846239) @ Episode 787/5000, loss: 0.0148611934855580335\n",
      "Episode 787, Reward: 4.0\n",
      "Step 425 (846665) @ Episode 788/5000, loss: 0.0111681120470166256\n",
      "Episode 788, Reward: 5.0\n",
      "Step 312 (846978) @ Episode 789/5000, loss: 0.0307619497179985055\n",
      "Episode 789, Reward: 3.0\n",
      "Step 242 (847221) @ Episode 790/5000, loss: 0.0115837547928094865\n",
      "Episode 790, Reward: 1.0\n",
      "Step 476 (847698) @ Episode 791/5000, loss: 0.0260306447744369585\n",
      "Episode 791, Reward: 5.0\n",
      "Step 458 (848157) @ Episode 792/5000, loss: 0.0042599984444677835\n",
      "Episode 792, Reward: 5.0\n",
      "Step 337 (848495) @ Episode 793/5000, loss: 0.0145785612985491755\n",
      "Episode 793, Reward: 3.0\n",
      "Step 416 (848912) @ Episode 794/5000, loss: 0.0081671718508005145\n",
      "Episode 794, Reward: 5.0\n",
      "Step 229 (849142) @ Episode 795/5000, loss: 0.0189815759658813485\n",
      "Episode 795, Reward: 1.0\n",
      "Step 294 (849437) @ Episode 796/5000, loss: 0.0115642771124839785\n",
      "Episode 796, Reward: 3.0\n",
      "Step 301 (849739) @ Episode 797/5000, loss: 0.0115706622600555425\n",
      "Episode 797, Reward: 2.0\n",
      "Step 405 (850145) @ Episode 798/5000, loss: 0.0064090564846992496\n",
      "Episode 798, Reward: 5.0\n",
      "Step 212 (850358) @ Episode 799/5000, loss: 0.0054227570071816444\n",
      "Episode 799, Reward: 1.0\n",
      "Step 203 (850562) @ Episode 800/5000, loss: 0.0114371404051780795\n",
      "Episode 800, Reward: 1.0\n",
      "Step 253 (850816) @ Episode 801/5000, loss: 0.0094136428087949755\n",
      "Episode 801, Reward: 2.0\n",
      "Step 414 (851231) @ Episode 802/5000, loss: 0.0128236953169107445\n",
      "Episode 802, Reward: 4.0\n",
      "Step 475 (851707) @ Episode 803/5000, loss: 0.0167698320001363754\n",
      "Episode 803, Reward: 7.0\n",
      "Step 486 (852194) @ Episode 804/5000, loss: 0.0086003579199314125\n",
      "Episode 804, Reward: 6.0\n",
      "Step 287 (852482) @ Episode 805/5000, loss: 0.0098294001072645195\n",
      "Episode 805, Reward: 2.0\n",
      "Step 402 (852885) @ Episode 806/5000, loss: 0.0138116627931594855\n",
      "Episode 806, Reward: 3.0\n",
      "Step 258 (853144) @ Episode 807/5000, loss: 0.0129762981086969385"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "\n",
    "env = gym.make('Breakout-v0')\n",
    "\n",
    "# Where we save our checkpoints and graphs\n",
    "experiment_dir = os.path.abspath(\"./experiments/{}\".format(env.spec.id))\n",
    "\n",
    "q_network = Qnetwork(84, 4, env.action_space.n, global_step, scope='estimator', summaries_dir=experiment_dir)\n",
    "target_network = Qnetwork(84, 4, env.action_space.n, global_step, scope='target')\n",
    "\n",
    "state_processor = StateProcessor()\n",
    "\n",
    "replay_buffer = ReplayBuffer(size=500000)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # copy network to target\n",
    "    copy_model_parameters(sess, q_network, target_network)\n",
    "    rewards, lengths = train_dqn(sess=sess,\n",
    "              env=env,\n",
    "              q_network=q_network,\n",
    "              target_network=target_network,\n",
    "              state_processor=state_processor,\n",
    "              num_episodes=5000,\n",
    "              global_step=global_step,\n",
    "              experiment_dir=experiment_dir,\n",
    "              replay_buffer=replay_buffer,\n",
    "              buffer_init_size=10000,\n",
    "              target_interval=10000,\n",
    "              frame_skip=1,\n",
    "              epsilon_start=1,\n",
    "              epsilon_end=0.1,\n",
    "              epsilon_decay_length=500000,\n",
    "              gamma=0.99,\n",
    "              batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 470.])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
